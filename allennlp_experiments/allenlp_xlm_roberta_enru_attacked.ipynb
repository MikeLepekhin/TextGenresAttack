{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mseven              \u001b[m  Thu Mar  4 18:04:31 2021  \u001b[1m\u001b[30m440.64\u001b[m\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mTITAN RTX       \u001b[m |\u001b[1m\u001b[31m 86'C\u001b[m, \u001b[1m\u001b[32m 83 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m17140\u001b[m / \u001b[33m24220\u001b[m MB | \u001b[1m\u001b[30msharuev\u001b[m(\u001b[33m1649M\u001b[m) \u001b[1m\u001b[30msharuev\u001b[m(\u001b[33m12931M\u001b[m) \u001b[1m\u001b[30msharuev\u001b[m(\u001b[33m2549M\u001b[m)\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mTITAN RTX       \u001b[m |\u001b[1m\u001b[31m 87'C\u001b[m, \u001b[1m\u001b[32m 98 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m10230\u001b[m / \u001b[33m24220\u001b[m MB | \u001b[1m\u001b[30mcwb\u001b[m(\u001b[33m3297M\u001b[m) \u001b[1m\u001b[30mcwb\u001b[m(\u001b[33m3955M\u001b[m) \u001b[1m\u001b[30mcwb\u001b[m(\u001b[33m2967M\u001b[m)\r\n",
      "\u001b[36m[2]\u001b[m \u001b[34mTITAN RTX       \u001b[m |\u001b[1m\u001b[31m 55'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   11\u001b[m / \u001b[33m24220\u001b[m MB |\r\n",
      "\u001b[36m[3]\u001b[m \u001b[34mTITAN RTX       \u001b[m |\u001b[1m\u001b[31m 86'C\u001b[m, \u001b[1m\u001b[32m 99 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 9156\u001b[m / \u001b[33m24220\u001b[m MB | \u001b[1m\u001b[30mcwb\u001b[m(\u001b[33m2917M\u001b[m) \u001b[1m\u001b[30mcwb\u001b[m(\u001b[33m3053M\u001b[m) \u001b[1m\u001b[30mcwb\u001b[m(\u001b[33m3175M\u001b[m)\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as pathjoin\n",
    "from data_processing import *\n",
    "from interpretation import *\n",
    "from models import *\n",
    "from training import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3397, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>changed_words_num</th>\n",
       "      <th>new_model_target</th>\n",
       "      <th>old_model_target</th>\n",
       "      <th>old_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>291</td>\n",
       "      <td>131.0</td>\n",
       "      <td>A1</td>\n",
       "      <td>Повседневное ТВ , ориентируясь на благополучие...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A8</td>\n",
       "      <td>вторник , 12 июля 2011 года , 11.24 « ВКонтакт...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A7</td>\n",
       "      <td>A8</td>\n",
       "      <td>вторник , 12 июля 2011 года , 11.24 « ВКонтакт...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2334</th>\n",
       "      <td>887</td>\n",
       "      <td>839.0</td>\n",
       "      <td>A17</td>\n",
       "      <td>The Acoustic Music Co : Folk music instrument ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>432</td>\n",
       "      <td>361.0</td>\n",
       "      <td>A17</td>\n",
       "      <td>Сабжекта не будет Жена купила журнал \" Идеи ва...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>479</td>\n",
       "      <td>815.0</td>\n",
       "      <td>A16</td>\n",
       "      <td>Статистическая комиссия Тридцать четвертая сес...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1 target  \\\n",
       "291          291         131.0     A1   \n",
       "25            25           NaN     A8   \n",
       "2334         887         839.0    A17   \n",
       "432          432         361.0    A17   \n",
       "479          479         815.0    A16   \n",
       "\n",
       "                                                   text  changed_words_num  \\\n",
       "291   Повседневное ТВ , ориентируясь на благополучие...                NaN   \n",
       "25    вторник , 12 июля 2011 года , 11.24 « ВКонтакт...                1.0   \n",
       "2334  The Acoustic Music Co : Folk music instrument ...                NaN   \n",
       "432   Сабжекта не будет Жена купила журнал \" Идеи ва...                NaN   \n",
       "479   Статистическая комиссия Тридцать четвертая сес...                NaN   \n",
       "\n",
       "     new_model_target old_model_target  \\\n",
       "291               NaN              NaN   \n",
       "25                 A7               A8   \n",
       "2334              NaN              NaN   \n",
       "432               NaN              NaN   \n",
       "479               NaN              NaN   \n",
       "\n",
       "                                               old_text  \n",
       "291                                                 NaN  \n",
       "25    вторник , 12 июля 2011 года , 11.24 « ВКонтакт...  \n",
       "2334                                                NaN  \n",
       "432                                                 NaN  \n",
       "479                                                 NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddd = pd.read_csv('enru_train.csv')\n",
    "ddd = ddd.append(pd.read_csv('/home/mlepekhin/data/new_ru_attacked.csv')).sample(frac=1, random_state=42)\n",
    "#ddd = ddd.append(pd.read_csv('/home/mlepekhin/data/en_attacked.csv'))\n",
    "print(ddd.shape)\n",
    "ddd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddd.to_csv('enru_attacked_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/mlepekhin/data'\n",
    "MODELS_DIR = '/home/mlepekhin/models'\n",
    "MODEL_ID = 'allennlp_xlm_roberta_enru_attacked' \n",
    "CHECKPOINTS_DIR = pathjoin(MODELS_DIR, MODEL_ID, 'checkpoints')\n",
    "BEST_MODEL = pathjoin(CHECKPOINTS_DIR, 'best.th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = 'xlm-roberta-base'\n",
    "MAX_TOKENS = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:10:05|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03042021 18:10:05|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "03042021 18:10:06|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /home/mlepekhin/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n",
      "03042021 18:10:07|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03042021 18:10:07|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "03042021 18:10:08|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /home/mlepekhin/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n"
     ]
    }
   ],
   "source": [
    "tokenizer = PretrainedTransformerTokenizer(transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:10:09|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03042021 18:10:09|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "03042021 18:10:09|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /home/mlepekhin/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n",
      "03042021 18:10:10|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03042021 18:10:10|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "03042021 18:10:11|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /home/mlepekhin/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n",
      "03042021 18:10:12|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03042021 18:10:12|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "03042021 18:10:13|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /home/mlepekhin/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n",
      "03042021 18:10:14|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03042021 18:10:14|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "03042021 18:10:14|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /home/mlepekhin/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n",
      "03042021 18:10:15|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03042021 18:10:15|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "03042021 18:10:16|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /home/mlepekhin/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n",
      "03042021 18:10:17|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03042021 18:10:17|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "03042021 18:10:17|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /home/mlepekhin/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n",
      "03042021 18:10:19|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03042021 18:10:19|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:10:19|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /home/mlepekhin/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n",
      "03042021 18:10:20|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03042021 18:10:20|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "03042021 18:10:21|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /home/mlepekhin/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n",
      "<class 'data_processing.ClassificationDatasetReader'> enru_attacked_train.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909dbf8baeba429b99247d60d022c2b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc440770f96a4b9b82937148ed87a1cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:15:45|INFO|allennlp.data.vocabulary| Fitting token dictionary from dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building the vocabulary\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92cf2b26021a4d2b92938d7656899c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6505.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset_reader = build_transformer_dataset_reader(transformer_model, lower=True)\n",
    "val_dataset_reader = build_transformer_dataset_reader(transformer_model, lower=True)\n",
    "\n",
    "train_data, dev_data = read_data(\n",
    "    \"enru_attacked_train.csv\", \n",
    "    pathjoin(DATA_DIR, \"manual_genres\", \"all.csv\"),\n",
    "    train_dataset_reader, \n",
    "    val_dataset_reader\n",
    ")\n",
    "\n",
    "vocab = build_vocab(train_data + dev_data)\n",
    "\n",
    "train_data.index_with(vocab)\n",
    "dev_data.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:15:46|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03042021 18:15:46|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "03042021 18:15:46|INFO|transformers.modeling_utils| loading weights file https://cdn.huggingface.co/xlm-roberta-base-pytorch_model.bin from cache at /home/mlepekhin/.cache/torch/transformers/5cbeb972feded79b927818648bf14dc71b7810cda88c8c971a9d45c0dab901ec.aeeaca90954dc20ffa2909de722cfbfd455c5bb16d480c5bdf6d7fe79c68c267\n",
      "03042021 18:15:57|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03042021 18:15:57|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "03042021 18:15:58|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /home/mlepekhin/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n",
      "03042021 18:15:59|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03042021 18:15:59|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "03042021 18:16:00|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /home/mlepekhin/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n"
     ]
    }
   ],
   "source": [
    "model = build_pool_transformer_model(vocab, transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    cuda_device = 2\n",
    "    model = model.cuda(cuda_device)\n",
    "else:\n",
    "    cuda_device = -1\n",
    "print(cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {CHECKPOINTS_DIR}\n",
    "!mkdir -p {CHECKPOINTS_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:16:06|INFO|allennlp.training.optimizers| Number of trainable parameters: 278052107\n",
      "03042021 18:16:06|WARNING|allennlp.training.trainer| You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n",
      "03042021 18:16:06|INFO|allennlp.training.trainer| Beginning training.\n",
      "03042021 18:16:06|INFO|allennlp.training.trainer| Epoch 0/9\n",
      "03042021 18:16:06|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5792.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:16:06|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 17140\n",
      "03042021 18:16:06|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 10230\n",
      "03042021 18:16:06|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 1990\n",
      "03042021 18:16:06|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9156\n",
      "03042021 18:16:06|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24da29bbe644e6cb07706b075a9ad85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=213.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:18:03|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "979b6c4da2e146f1be3b94b1b646608a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=195.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:18:39|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03042021 18:18:39|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.665  |     0.707\n",
      "03042021 18:18:39|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  17140.000  |       N/A\n",
      "03042021 18:18:39|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  10230.000  |       N/A\n",
      "03042021 18:18:39|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  1990.000  |       N/A\n",
      "03042021 18:18:39|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9156.000  |       N/A\n",
      "03042021 18:18:39|INFO|allennlp.training.tensorboard_writer| loss               |     1.079  |     0.918\n",
      "03042021 18:18:39|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03042021 18:18:39|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5792.840  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:18:43|INFO|allennlp.training.checkpointer| Best validation performance so far. Copying weights to '/home/mlepekhin/models/allennlp_xlm_roberta_enru_attacked/checkpoints/best.th'.\n",
      "03042021 18:18:43|INFO|allennlp.training.trainer| Epoch duration: 0:02:37.934599\n",
      "03042021 18:18:43|INFO|allennlp.training.trainer| Estimated training time remaining: 0:23:41\n",
      "03042021 18:18:43|INFO|allennlp.training.trainer| Epoch 1/9\n",
      "03042021 18:18:43|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5792.84\n",
      "03042021 18:18:44|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 17140\n",
      "03042021 18:18:44|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 10230\n",
      "03042021 18:18:44|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 18470\n",
      "03042021 18:18:44|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9156\n",
      "03042021 18:18:44|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff34dfcd3a4149d2ac7bf0696341dae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=213.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:20:42|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709ec772e5524c24bb4ce7430afa84a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=195.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:21:18|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03042021 18:21:18|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.829  |     0.708\n",
      "03042021 18:21:18|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  17140.000  |       N/A\n",
      "03042021 18:21:18|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  10230.000  |       N/A\n",
      "03042021 18:21:18|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  18470.000  |       N/A\n",
      "03042021 18:21:18|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9156.000  |       N/A\n",
      "03042021 18:21:18|INFO|allennlp.training.tensorboard_writer| loss               |     0.554  |     0.912\n",
      "03042021 18:21:18|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03042021 18:21:18|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5792.840  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:21:22|INFO|allennlp.training.checkpointer| Best validation performance so far. Copying weights to '/home/mlepekhin/models/allennlp_xlm_roberta_enru_attacked/checkpoints/best.th'.\n",
      "03042021 18:21:29|INFO|allennlp.training.trainer| Epoch duration: 0:02:45.158569\n",
      "03042021 18:21:29|INFO|allennlp.training.trainer| Estimated training time remaining: 0:21:32\n",
      "03042021 18:21:29|INFO|allennlp.training.trainer| Epoch 2/9\n",
      "03042021 18:21:29|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5792.84\n",
      "03042021 18:21:29|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 17140\n",
      "03042021 18:21:29|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 10230\n",
      "03042021 18:21:29|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 18470\n",
      "03042021 18:21:29|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9156\n",
      "03042021 18:21:29|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ebf8329ef54af4be5a820442cb2051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=213.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:23:27|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce54dd2adc66483fa5a5f0916be2c6a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=195.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:24:02|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03042021 18:24:02|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.884  |     0.754\n",
      "03042021 18:24:02|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  17140.000  |       N/A\n",
      "03042021 18:24:02|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  10230.000  |       N/A\n",
      "03042021 18:24:02|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  18470.000  |       N/A\n",
      "03042021 18:24:02|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9156.000  |       N/A\n",
      "03042021 18:24:02|INFO|allennlp.training.tensorboard_writer| loss               |     0.363  |     0.840\n",
      "03042021 18:24:02|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03042021 18:24:02|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5792.840  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:24:08|INFO|allennlp.training.checkpointer| Best validation performance so far. Copying weights to '/home/mlepekhin/models/allennlp_xlm_roberta_enru_attacked/checkpoints/best.th'.\n",
      "03042021 18:24:19|INFO|allennlp.training.trainer| Epoch duration: 0:02:49.901833\n",
      "03042021 18:24:19|INFO|allennlp.training.trainer| Estimated training time remaining: 0:19:10\n",
      "03042021 18:24:19|INFO|allennlp.training.trainer| Epoch 3/9\n",
      "03042021 18:24:19|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5792.84\n",
      "03042021 18:24:19|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 17140\n",
      "03042021 18:24:19|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 10230\n",
      "03042021 18:24:19|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 18470\n",
      "03042021 18:24:19|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9156\n",
      "03042021 18:24:19|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5b121bc4364029bb001afd381c9de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=213.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:26:17|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6897c329034f908d5dc2794e8c3d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=195.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:26:52|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03042021 18:26:52|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.934  |     0.717\n",
      "03042021 18:26:52|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  17140.000  |       N/A\n",
      "03042021 18:26:52|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  10230.000  |       N/A\n",
      "03042021 18:26:52|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  18470.000  |       N/A\n",
      "03042021 18:26:52|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9156.000  |       N/A\n",
      "03042021 18:26:52|INFO|allennlp.training.tensorboard_writer| loss               |     0.218  |     1.053\n",
      "03042021 18:26:52|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03042021 18:26:52|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5792.840  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:26:56|INFO|allennlp.training.trainer| Epoch duration: 0:02:37.669729\n",
      "03042021 18:26:56|INFO|allennlp.training.trainer| Estimated training time remaining: 0:16:16\n",
      "03042021 18:26:56|INFO|allennlp.training.trainer| Epoch 4/9\n",
      "03042021 18:26:56|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5792.84\n",
      "03042021 18:26:56|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 17140\n",
      "03042021 18:26:56|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 10230\n",
      "03042021 18:26:56|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 18470\n",
      "03042021 18:26:56|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9156\n",
      "03042021 18:26:56|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e39582b0a2743ceba06a6aa13a50f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=213.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:28:55|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3f7e6b1ea14a5fa6446dcc1127f1d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=195.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:29:30|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03042021 18:29:30|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.960  |     0.688\n",
      "03042021 18:29:30|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  17140.000  |       N/A\n",
      "03042021 18:29:30|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  10230.000  |       N/A\n",
      "03042021 18:29:30|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  18470.000  |       N/A\n",
      "03042021 18:29:30|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9156.000  |       N/A\n",
      "03042021 18:29:30|INFO|allennlp.training.tensorboard_writer| loss               |     0.136  |     1.313\n",
      "03042021 18:29:30|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03042021 18:29:30|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5792.840  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:29:35|INFO|allennlp.training.trainer| Epoch duration: 0:02:38.431892\n",
      "03042021 18:29:35|INFO|allennlp.training.trainer| Estimated training time remaining: 0:13:29\n",
      "03042021 18:29:35|INFO|allennlp.training.trainer| Epoch 5/9\n",
      "03042021 18:29:35|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5792.84\n",
      "03042021 18:29:35|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 17140\n",
      "03042021 18:29:35|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 10230\n",
      "03042021 18:29:35|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 18470\n",
      "03042021 18:29:35|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9156\n",
      "03042021 18:29:35|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463bc324f6e943f9851e43cf2a9f8304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=213.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:31:33|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b89c5a51d404d738b2aeca4116d2788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=195.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:32:09|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03042021 18:32:09|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.969  |     0.726\n",
      "03042021 18:32:09|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  17140.000  |       N/A\n",
      "03042021 18:32:09|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  10230.000  |       N/A\n",
      "03042021 18:32:09|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  18470.000  |       N/A\n",
      "03042021 18:32:09|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9156.000  |       N/A\n",
      "03042021 18:32:09|INFO|allennlp.training.tensorboard_writer| loss               |     0.103  |     1.153\n",
      "03042021 18:32:09|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03042021 18:32:09|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5792.840  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:32:14|INFO|allennlp.training.trainer| Epoch duration: 0:02:39.722837\n",
      "03042021 18:32:14|INFO|allennlp.training.trainer| Estimated training time remaining: 0:10:45\n",
      "03042021 18:32:14|INFO|allennlp.training.trainer| Epoch 6/9\n",
      "03042021 18:32:14|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5792.84\n",
      "03042021 18:32:15|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 17140\n",
      "03042021 18:32:15|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 10230\n",
      "03042021 18:32:15|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 18470\n",
      "03042021 18:32:15|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9156\n",
      "03042021 18:32:15|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ebffbe30d04f58981854e498f8c80d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=213.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:34:13|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa93a97b42d548708efe5c5f5d8e8c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=195.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:34:48|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03042021 18:34:48|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.984  |     0.753\n",
      "03042021 18:34:48|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  17140.000  |       N/A\n",
      "03042021 18:34:48|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  10230.000  |       N/A\n",
      "03042021 18:34:48|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  18470.000  |       N/A\n",
      "03042021 18:34:48|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9156.000  |       N/A\n",
      "03042021 18:34:48|INFO|allennlp.training.tensorboard_writer| loss               |     0.061  |     1.150\n",
      "03042021 18:34:48|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03042021 18:34:48|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5792.840  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:34:52|INFO|allennlp.training.trainer| Epoch duration: 0:02:38.003060\n",
      "03042021 18:34:52|INFO|allennlp.training.trainer| Estimated training time remaining: 0:08:02\n",
      "03042021 18:34:52|INFO|allennlp.training.trainer| Epoch 7/9\n",
      "03042021 18:34:52|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5792.84\n",
      "03042021 18:34:53|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 17140\n",
      "03042021 18:34:53|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 10230\n",
      "03042021 18:34:53|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 18470\n",
      "03042021 18:34:53|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9156\n",
      "03042021 18:34:53|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80525962a3c4f0c94a2f97bcda3dad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=213.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:36:51|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feed6bde5c73438e8e42c3d959089c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=195.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:37:27|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03042021 18:37:27|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.983  |     0.725\n",
      "03042021 18:37:27|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  17140.000  |       N/A\n",
      "03042021 18:37:27|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  10230.000  |       N/A\n",
      "03042021 18:37:27|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  18470.000  |       N/A\n",
      "03042021 18:37:27|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9156.000  |       N/A\n",
      "03042021 18:37:27|INFO|allennlp.training.tensorboard_writer| loss               |     0.058  |     1.247\n",
      "03042021 18:37:27|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03042021 18:37:27|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5792.840  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:37:31|INFO|allennlp.training.trainer| Epoch duration: 0:02:39.018585\n",
      "03042021 18:37:31|INFO|allennlp.training.trainer| Estimated training time remaining: 0:05:21\n",
      "03042021 18:37:31|INFO|allennlp.training.trainer| Epoch 8/9\n",
      "03042021 18:37:31|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5792.84\n",
      "03042021 18:37:32|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 17140\n",
      "03042021 18:37:32|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 10230\n",
      "03042021 18:37:32|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 18470\n",
      "03042021 18:37:32|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9156\n",
      "03042021 18:37:32|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "659d99043f6f410d883331d0b2028ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=213.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:39:30|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72e991453a646a094e5991999df1bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=195.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:40:05|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03042021 18:40:05|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.980  |     0.713\n",
      "03042021 18:40:05|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  17140.000  |       N/A\n",
      "03042021 18:40:05|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  10230.000  |       N/A\n",
      "03042021 18:40:05|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  18470.000  |       N/A\n",
      "03042021 18:40:05|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9156.000  |       N/A\n",
      "03042021 18:40:05|INFO|allennlp.training.tensorboard_writer| loss               |     0.062  |     1.383\n",
      "03042021 18:40:05|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03042021 18:40:05|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5792.840  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:40:10|INFO|allennlp.training.trainer| Epoch duration: 0:02:39.041847\n",
      "03042021 18:40:10|INFO|allennlp.training.trainer| Estimated training time remaining: 0:02:40\n",
      "03042021 18:40:10|INFO|allennlp.training.trainer| Epoch 9/9\n",
      "03042021 18:40:10|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5792.84\n",
      "03042021 18:40:11|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 17140\n",
      "03042021 18:40:11|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 10230\n",
      "03042021 18:40:11|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 18470\n",
      "03042021 18:40:11|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9156\n",
      "03042021 18:40:11|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1c04fca37148e8813b5ff4665b01d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=213.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:42:09|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec41498e74146a1b99fa917d97e9a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=195.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:42:44|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03042021 18:42:44|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.985  |     0.729\n",
      "03042021 18:42:44|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  17140.000  |       N/A\n",
      "03042021 18:42:44|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  10230.000  |       N/A\n",
      "03042021 18:42:44|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  18470.000  |       N/A\n",
      "03042021 18:42:44|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9156.000  |       N/A\n",
      "03042021 18:42:44|INFO|allennlp.training.tensorboard_writer| loss               |     0.051  |     1.242\n",
      "03042021 18:42:44|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03042021 18:42:44|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5792.840  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:42:49|INFO|allennlp.training.trainer| Epoch duration: 0:02:38.318316\n",
      "03042021 18:42:49|INFO|allennlp.training.checkpointer| loading best weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "train_loader, dev_loader = build_data_loaders(train_data, dev_data)\n",
    "\n",
    "# You obviously won't want to create a temporary file for your training\n",
    "# results, but for execution in binder for this course, we need to do this.\n",
    "\n",
    "trainer = build_classifier_trainer(\n",
    "    model,\n",
    "    pathjoin(MODELS_DIR, MODEL_ID, 'checkpoints'),\n",
    "    train_loader,\n",
    "    dev_loader,\n",
    "    10,\n",
    "    cuda_device=cuda_device\n",
    ")\n",
    "print(\"Starting training\")\n",
    "trainer.train()\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03042021 18:42:51|WARNING|root| vocabulary serialization directory /home/mlepekhin/models/allennlp_xlm_roberta_enru_attacked/vocab is not empty\n",
      "03042021 18:42:51|INFO|filelock| Lock 140228623927472 acquired on /home/mlepekhin/models/allennlp_xlm_roberta_enru_attacked/vocab/.lock\n",
      "03042021 18:42:51|INFO|filelock| Lock 140228623927472 released on /home/mlepekhin/models/allennlp_xlm_roberta_enru_attacked/vocab/.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1,1G\r\n",
      "-rw-rw-r-- 1 mlepekhin mlepekhin 1,1G мар  4 18:24 best.th\r\n",
      "drwxrwxr-x 4 mlepekhin mlepekhin 4,0K мар  4 18:16 log\r\n"
     ]
    }
   ],
   "source": [
    "!rm \"{CHECKPOINTS_DIR}\"/*.json \"{CHECKPOINTS_DIR}\"/model* \"{CHECKPOINTS_DIR}\"/training*\n",
    "model.vocab.save_to_files(pathjoin(MODELS_DIR, MODEL_ID, 'vocab'))\n",
    "!ls -lh \"{CHECKPOINTS_DIR}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
