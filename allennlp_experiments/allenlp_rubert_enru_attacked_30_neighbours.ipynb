{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mseven              \u001b[m  Thu Mar 11 09:49:14 2021  \u001b[1m\u001b[30m440.64\u001b[m\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mTITAN RTX       \u001b[m |\u001b[31m 36'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   11\u001b[m / \u001b[33m24220\u001b[m MB |\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mTITAN RTX       \u001b[m |\u001b[1m\u001b[31m 85'C\u001b[m, \u001b[1m\u001b[32m 40 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 2662\u001b[m / \u001b[33m24220\u001b[m MB | \u001b[1m\u001b[30mcwb\u001b[m(\u001b[33m2651M\u001b[m)\r\n",
      "\u001b[36m[2]\u001b[m \u001b[34mTITAN RTX       \u001b[m |\u001b[31m 33'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   11\u001b[m / \u001b[33m24220\u001b[m MB |\r\n",
      "\u001b[36m[3]\u001b[m \u001b[34mTITAN RTX       \u001b[m |\u001b[1m\u001b[31m 87'C\u001b[m, \u001b[1m\u001b[32m 98 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 9928\u001b[m / \u001b[33m24220\u001b[m MB | \u001b[1m\u001b[30mcwb\u001b[m(\u001b[33m3411M\u001b[m) \u001b[1m\u001b[30mcwb\u001b[m(\u001b[33m3063M\u001b[m) \u001b[1m\u001b[30mcwb\u001b[m(\u001b[33m3443M\u001b[m)\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as pathjoin\n",
    "from data_processing import *\n",
    "from interpretation import *\n",
    "from models import *\n",
    "from training import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3867, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>changed_words_num</th>\n",
       "      <th>new_model_target</th>\n",
       "      <th>old_model_target</th>\n",
       "      <th>old_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>141</td>\n",
       "      <td>A1</td>\n",
       "      <td>A great way to start , I think , with my view ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>528</td>\n",
       "      <td>A1</td>\n",
       "      <td>Реакция курильщиков на вторую волну антитабачн...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>1049</td>\n",
       "      <td>A9</td>\n",
       "      <td>1 . - ( 1 ) The corporation sole by the name o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1121</td>\n",
       "      <td>A12</td>\n",
       "      <td>We noticed that you 're using an unsupported b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>1755</td>\n",
       "      <td>A14</td>\n",
       "      <td>ПЕРВЫЕ РЕЗУЛЬТАТЫ ЭКСПЕРИМЕНТА ПО РАДИОЛОКАЦИИ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 target                                               text  \\\n",
       "727          141     A1  A great way to start , I think , with my view ...   \n",
       "1420         528     A1  Реакция курильщиков на вторую волну антитабачн...   \n",
       "1031        1049     A9  1 . - ( 1 ) The corporation sole by the name o...   \n",
       "137         1121    A12  We noticed that you 're using an unsupported b...   \n",
       "952         1755    A14  ПЕРВЫЕ РЕЗУЛЬТАТЫ ЭКСПЕРИМЕНТА ПО РАДИОЛОКАЦИИ...   \n",
       "\n",
       "      changed_words_num new_model_target old_model_target old_text  \n",
       "727                 NaN              NaN              NaN      NaN  \n",
       "1420                NaN              NaN              NaN      NaN  \n",
       "1031                NaN              NaN              NaN      NaN  \n",
       "137                 NaN              NaN              NaN      NaN  \n",
       "952                 NaN              NaN              NaN      NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddd = pd.read_csv('/home/mlepekhin/data/ru_train')\n",
    "ddd = ddd.append(pd.read_csv('/home/mlepekhin/data/en_train'))\n",
    "ddd = ddd.append(pd.read_csv('/home/mlepekhin/data/new_ru_attacked_30.csv'))\n",
    "ddd = ddd.append(pd.read_csv('/home/mlepekhin/data/en_attacked_30.csv')).sample(frac=1, random_state=42)\n",
    "print(ddd.shape)\n",
    "ddd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddd.to_csv('enru_attacked_train_30.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/mlepekhin/data'\n",
    "MODELS_DIR = '/home/mlepekhin/models'\n",
    "MODEL_ID = 'rubert_enru_attacked_30' \n",
    "CHECKPOINTS_DIR = pathjoin(MODELS_DIR, MODEL_ID, 'checkpoints')\n",
    "BEST_MODEL = pathjoin(CHECKPOINTS_DIR, 'best.th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = 'DeepPavlov/rubert-base-cased'\n",
    "MAX_TOKENS = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 09:49:41|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03112021 09:49:41|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "03112021 09:49:41|INFO|transformers.tokenization_utils| Model name 'DeepPavlov/rubert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'DeepPavlov/rubert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03112021 09:49:43|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/vocab.txt from cache at /home/mlepekhin/.cache/torch/transformers/3e164bb7396e401202e250721569fb407583681bb6ea0c34f431af622435a3d8.67d40fedd426f94e9ea8d75f879bbc353613af6b908324e8eca582d4cfa9b0eb\n",
      "03112021 09:49:43|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/added_tokens.json from cache at None\n",
      "03112021 09:49:43|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/special_tokens_map.json from cache at /home/mlepekhin/.cache/torch/transformers/d44047cea679f35c9ce4f09172821fc62d3b493f77e63d3aeffd42f51df90ce9.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "03112021 09:49:43|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/tokenizer_config.json from cache at /home/mlepekhin/.cache/torch/transformers/1db6339329fc47780d55cc00813fef2f7a1e4b802ec31509975c82b8a7d74e4e.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n",
      "03112021 09:49:44|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03112021 09:49:44|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "03112021 09:49:44|INFO|transformers.tokenization_utils| Model name 'DeepPavlov/rubert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'DeepPavlov/rubert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03112021 09:49:46|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/vocab.txt from cache at /home/mlepekhin/.cache/torch/transformers/3e164bb7396e401202e250721569fb407583681bb6ea0c34f431af622435a3d8.67d40fedd426f94e9ea8d75f879bbc353613af6b908324e8eca582d4cfa9b0eb\n",
      "03112021 09:49:46|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/added_tokens.json from cache at None\n",
      "03112021 09:49:46|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/special_tokens_map.json from cache at /home/mlepekhin/.cache/torch/transformers/d44047cea679f35c9ce4f09172821fc62d3b493f77e63d3aeffd42f51df90ce9.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "03112021 09:49:46|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/tokenizer_config.json from cache at /home/mlepekhin/.cache/torch/transformers/1db6339329fc47780d55cc00813fef2f7a1e4b802ec31509975c82b8a7d74e4e.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n"
     ]
    }
   ],
   "source": [
    "tokenizer = PretrainedTransformerTokenizer(transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 09:50:08|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03112021 09:50:08|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "03112021 09:50:08|INFO|transformers.tokenization_utils| Model name 'DeepPavlov/rubert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'DeepPavlov/rubert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03112021 09:50:10|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/vocab.txt from cache at /home/mlepekhin/.cache/torch/transformers/3e164bb7396e401202e250721569fb407583681bb6ea0c34f431af622435a3d8.67d40fedd426f94e9ea8d75f879bbc353613af6b908324e8eca582d4cfa9b0eb\n",
      "03112021 09:50:10|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/added_tokens.json from cache at None\n",
      "03112021 09:50:10|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/special_tokens_map.json from cache at /home/mlepekhin/.cache/torch/transformers/d44047cea679f35c9ce4f09172821fc62d3b493f77e63d3aeffd42f51df90ce9.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "03112021 09:50:10|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/tokenizer_config.json from cache at /home/mlepekhin/.cache/torch/transformers/1db6339329fc47780d55cc00813fef2f7a1e4b802ec31509975c82b8a7d74e4e.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n",
      "03112021 09:50:11|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03112021 09:50:11|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "03112021 09:50:11|INFO|transformers.tokenization_utils| Model name 'DeepPavlov/rubert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'DeepPavlov/rubert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03112021 09:50:13|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/vocab.txt from cache at /home/mlepekhin/.cache/torch/transformers/3e164bb7396e401202e250721569fb407583681bb6ea0c34f431af622435a3d8.67d40fedd426f94e9ea8d75f879bbc353613af6b908324e8eca582d4cfa9b0eb\n",
      "03112021 09:50:13|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/added_tokens.json from cache at None\n",
      "03112021 09:50:13|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/special_tokens_map.json from cache at /home/mlepekhin/.cache/torch/transformers/d44047cea679f35c9ce4f09172821fc62d3b493f77e63d3aeffd42f51df90ce9.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "03112021 09:50:13|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/tokenizer_config.json from cache at /home/mlepekhin/.cache/torch/transformers/1db6339329fc47780d55cc00813fef2f7a1e4b802ec31509975c82b8a7d74e4e.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n",
      "03112021 09:50:13|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03112021 09:50:13|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "03112021 09:50:13|INFO|transformers.tokenization_utils| Model name 'DeepPavlov/rubert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'DeepPavlov/rubert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 09:50:16|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/vocab.txt from cache at /home/mlepekhin/.cache/torch/transformers/3e164bb7396e401202e250721569fb407583681bb6ea0c34f431af622435a3d8.67d40fedd426f94e9ea8d75f879bbc353613af6b908324e8eca582d4cfa9b0eb\n",
      "03112021 09:50:16|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/added_tokens.json from cache at None\n",
      "03112021 09:50:16|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/special_tokens_map.json from cache at /home/mlepekhin/.cache/torch/transformers/d44047cea679f35c9ce4f09172821fc62d3b493f77e63d3aeffd42f51df90ce9.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "03112021 09:50:16|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/tokenizer_config.json from cache at /home/mlepekhin/.cache/torch/transformers/1db6339329fc47780d55cc00813fef2f7a1e4b802ec31509975c82b8a7d74e4e.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n",
      "03112021 09:50:16|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03112021 09:50:16|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "03112021 09:50:16|INFO|transformers.tokenization_utils| Model name 'DeepPavlov/rubert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'DeepPavlov/rubert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03112021 09:50:18|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/vocab.txt from cache at /home/mlepekhin/.cache/torch/transformers/3e164bb7396e401202e250721569fb407583681bb6ea0c34f431af622435a3d8.67d40fedd426f94e9ea8d75f879bbc353613af6b908324e8eca582d4cfa9b0eb\n",
      "03112021 09:50:18|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/added_tokens.json from cache at None\n",
      "03112021 09:50:18|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/special_tokens_map.json from cache at /home/mlepekhin/.cache/torch/transformers/d44047cea679f35c9ce4f09172821fc62d3b493f77e63d3aeffd42f51df90ce9.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "03112021 09:50:18|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/tokenizer_config.json from cache at /home/mlepekhin/.cache/torch/transformers/1db6339329fc47780d55cc00813fef2f7a1e4b802ec31509975c82b8a7d74e4e.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n",
      "03112021 09:50:19|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03112021 09:50:19|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "03112021 09:50:19|INFO|transformers.tokenization_utils| Model name 'DeepPavlov/rubert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'DeepPavlov/rubert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03112021 09:50:21|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/vocab.txt from cache at /home/mlepekhin/.cache/torch/transformers/3e164bb7396e401202e250721569fb407583681bb6ea0c34f431af622435a3d8.67d40fedd426f94e9ea8d75f879bbc353613af6b908324e8eca582d4cfa9b0eb\n",
      "03112021 09:50:21|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/added_tokens.json from cache at None\n",
      "03112021 09:50:21|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/special_tokens_map.json from cache at /home/mlepekhin/.cache/torch/transformers/d44047cea679f35c9ce4f09172821fc62d3b493f77e63d3aeffd42f51df90ce9.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "03112021 09:50:21|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/tokenizer_config.json from cache at /home/mlepekhin/.cache/torch/transformers/1db6339329fc47780d55cc00813fef2f7a1e4b802ec31509975c82b8a7d74e4e.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n",
      "03112021 09:50:22|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03112021 09:50:22|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 09:50:22|INFO|transformers.tokenization_utils| Model name 'DeepPavlov/rubert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'DeepPavlov/rubert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03112021 09:50:24|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/vocab.txt from cache at /home/mlepekhin/.cache/torch/transformers/3e164bb7396e401202e250721569fb407583681bb6ea0c34f431af622435a3d8.67d40fedd426f94e9ea8d75f879bbc353613af6b908324e8eca582d4cfa9b0eb\n",
      "03112021 09:50:24|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/added_tokens.json from cache at None\n",
      "03112021 09:50:24|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/special_tokens_map.json from cache at /home/mlepekhin/.cache/torch/transformers/d44047cea679f35c9ce4f09172821fc62d3b493f77e63d3aeffd42f51df90ce9.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "03112021 09:50:24|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/tokenizer_config.json from cache at /home/mlepekhin/.cache/torch/transformers/1db6339329fc47780d55cc00813fef2f7a1e4b802ec31509975c82b8a7d74e4e.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n",
      "03112021 09:50:25|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03112021 09:50:25|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "03112021 09:50:25|INFO|transformers.tokenization_utils| Model name 'DeepPavlov/rubert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'DeepPavlov/rubert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03112021 09:50:27|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/vocab.txt from cache at /home/mlepekhin/.cache/torch/transformers/3e164bb7396e401202e250721569fb407583681bb6ea0c34f431af622435a3d8.67d40fedd426f94e9ea8d75f879bbc353613af6b908324e8eca582d4cfa9b0eb\n",
      "03112021 09:50:27|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/added_tokens.json from cache at None\n",
      "03112021 09:50:27|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/special_tokens_map.json from cache at /home/mlepekhin/.cache/torch/transformers/d44047cea679f35c9ce4f09172821fc62d3b493f77e63d3aeffd42f51df90ce9.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "03112021 09:50:27|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/tokenizer_config.json from cache at /home/mlepekhin/.cache/torch/transformers/1db6339329fc47780d55cc00813fef2f7a1e4b802ec31509975c82b8a7d74e4e.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n",
      "03112021 09:50:27|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03112021 09:50:27|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "03112021 09:50:27|INFO|transformers.tokenization_utils| Model name 'DeepPavlov/rubert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'DeepPavlov/rubert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03112021 09:50:30|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/vocab.txt from cache at /home/mlepekhin/.cache/torch/transformers/3e164bb7396e401202e250721569fb407583681bb6ea0c34f431af622435a3d8.67d40fedd426f94e9ea8d75f879bbc353613af6b908324e8eca582d4cfa9b0eb\n",
      "03112021 09:50:30|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/added_tokens.json from cache at None\n",
      "03112021 09:50:30|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/special_tokens_map.json from cache at /home/mlepekhin/.cache/torch/transformers/d44047cea679f35c9ce4f09172821fc62d3b493f77e63d3aeffd42f51df90ce9.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "03112021 09:50:30|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/tokenizer_config.json from cache at /home/mlepekhin/.cache/torch/transformers/1db6339329fc47780d55cc00813fef2f7a1e4b802ec31509975c82b8a7d74e4e.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n",
      "<class 'data_processing.ClassificationDatasetReader'> enru_attacked_train_30.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c437a1ff1837415c9d4b917bf0c7b958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cebd58cd7e984fcfb4ceb7243904926e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 09:52:20|INFO|allennlp.data.vocabulary| Fitting token dictionary from dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building the vocabulary\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b08106ecc04047973e4335491fc6b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7420.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset_reader = build_transformer_dataset_reader(transformer_model, lower=True)\n",
    "val_dataset_reader = build_transformer_dataset_reader(transformer_model, lower=True)\n",
    "\n",
    "train_data, dev_data = read_data(\n",
    "    \"enru_attacked_train_30.csv\", \n",
    "    pathjoin(DATA_DIR, \"manual_genres\", \"all.csv\"),\n",
    "    train_dataset_reader, \n",
    "    val_dataset_reader\n",
    ")\n",
    "\n",
    "vocab = build_vocab(train_data + dev_data)\n",
    "\n",
    "train_data.index_with(vocab)\n",
    "dev_data.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 09:52:21|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03112021 09:52:21|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "03112021 09:52:21|INFO|transformers.modeling_utils| loading weights file https://cdn.huggingface.co/DeepPavlov/rubert-base-cased/pytorch_model.bin from cache at /home/mlepekhin/.cache/torch/transformers/611b8e3ce80c0751b16e01b0e7c133fffc388089408bb9ef7f8a2d60c9758fd3.71d8ad10edfcd7c68264ea03bc1b14e1f7b9c67affdfe8d6f96e1a6ce2c136ee\n",
      "03112021 09:52:25|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03112021 09:52:25|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "03112021 09:52:25|INFO|transformers.tokenization_utils| Model name 'DeepPavlov/rubert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'DeepPavlov/rubert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03112021 09:52:27|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/vocab.txt from cache at /home/mlepekhin/.cache/torch/transformers/3e164bb7396e401202e250721569fb407583681bb6ea0c34f431af622435a3d8.67d40fedd426f94e9ea8d75f879bbc353613af6b908324e8eca582d4cfa9b0eb\n",
      "03112021 09:52:27|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/added_tokens.json from cache at None\n",
      "03112021 09:52:27|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/special_tokens_map.json from cache at /home/mlepekhin/.cache/torch/transformers/d44047cea679f35c9ce4f09172821fc62d3b493f77e63d3aeffd42f51df90ce9.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "03112021 09:52:27|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/tokenizer_config.json from cache at /home/mlepekhin/.cache/torch/transformers/1db6339329fc47780d55cc00813fef2f7a1e4b802ec31509975c82b8a7d74e4e.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n",
      "03112021 09:52:28|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03112021 09:52:28|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "03112021 09:52:28|INFO|transformers.tokenization_utils| Model name 'DeepPavlov/rubert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'DeepPavlov/rubert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03112021 09:52:30|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/vocab.txt from cache at /home/mlepekhin/.cache/torch/transformers/3e164bb7396e401202e250721569fb407583681bb6ea0c34f431af622435a3d8.67d40fedd426f94e9ea8d75f879bbc353613af6b908324e8eca582d4cfa9b0eb\n",
      "03112021 09:52:30|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/added_tokens.json from cache at None\n",
      "03112021 09:52:30|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/special_tokens_map.json from cache at /home/mlepekhin/.cache/torch/transformers/d44047cea679f35c9ce4f09172821fc62d3b493f77e63d3aeffd42f51df90ce9.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "03112021 09:52:30|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/tokenizer_config.json from cache at /home/mlepekhin/.cache/torch/transformers/1db6339329fc47780d55cc00813fef2f7a1e4b802ec31509975c82b8a7d74e4e.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n",
      "03112021 09:52:31|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03112021 09:52:31|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 09:52:31|INFO|transformers.modeling_utils| loading weights file https://cdn.huggingface.co/DeepPavlov/rubert-base-cased/pytorch_model.bin from cache at /home/mlepekhin/.cache/torch/transformers/611b8e3ce80c0751b16e01b0e7c133fffc388089408bb9ef7f8a2d60c9758fd3.71d8ad10edfcd7c68264ea03bc1b14e1f7b9c67affdfe8d6f96e1a6ce2c136ee\n"
     ]
    }
   ],
   "source": [
    "model = build_transformer_model(vocab, transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    cuda_device = 2\n",
    "    model = model.cuda(cuda_device)\n",
    "else:\n",
    "    cuda_device = -1\n",
    "print(cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {CHECKPOINTS_DIR}\n",
    "!mkdir -p {CHECKPOINTS_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 09:52:37|INFO|allennlp.training.optimizers| Number of trainable parameters: 178452491\n",
      "03112021 09:52:37|WARNING|allennlp.training.trainer| You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n",
      "03112021 09:52:37|INFO|allennlp.training.trainer| Beginning training.\n",
      "03112021 09:52:37|INFO|allennlp.training.trainer| Epoch 0/9\n",
      "03112021 09:52:37|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5634.928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 09:52:38|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 16656\n",
      "03112021 09:52:38|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03112021 09:52:38|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 1608\n",
      "03112021 09:52:38|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03112021 09:52:38|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57d01c90bed4fcd96491edb03484dac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=242.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 09:54:45|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d0b83d3e5b45d3a8c67059994a0299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 09:55:26|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03112021 09:55:26|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.572  |     0.692\n",
      "03112021 09:55:26|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  16656.000  |       N/A\n",
      "03112021 09:55:26|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03112021 09:55:26|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  1608.000  |       N/A\n",
      "03112021 09:55:26|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03112021 09:55:26|INFO|allennlp.training.tensorboard_writer| loss               |     1.375  |     0.975\n",
      "03112021 09:55:26|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03112021 09:55:26|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5634.928  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 09:55:29|INFO|allennlp.training.checkpointer| Best validation performance so far. Copying weights to '/home/mlepekhin/models/rubert_enru_attacked_30/checkpoints/best.th'.\n",
      "03112021 09:55:29|INFO|allennlp.training.trainer| Epoch duration: 0:02:51.788791\n",
      "03112021 09:55:29|INFO|allennlp.training.trainer| Estimated training time remaining: 0:25:46\n",
      "03112021 09:55:29|INFO|allennlp.training.trainer| Epoch 1/9\n",
      "03112021 09:55:29|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5634.928\n",
      "03112021 09:55:29|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 16710\n",
      "03112021 09:55:29|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03112021 09:55:29|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 16710\n",
      "03112021 09:55:29|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03112021 09:55:29|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67773e11f51a46309e858e9ad03638d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=242.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 09:57:40|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0361ec5c35f74315aa96a804825b0c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 09:58:20|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03112021 09:58:20|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.777  |     0.692\n",
      "03112021 09:58:20|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  16710.000  |       N/A\n",
      "03112021 09:58:20|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03112021 09:58:20|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  16710.000  |       N/A\n",
      "03112021 09:58:20|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03112021 09:58:20|INFO|allennlp.training.tensorboard_writer| loss               |     0.714  |     1.019\n",
      "03112021 09:58:20|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03112021 09:58:20|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5634.928  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 09:58:23|INFO|allennlp.training.checkpointer| Best validation performance so far. Copying weights to '/home/mlepekhin/models/rubert_enru_attacked_30/checkpoints/best.th'.\n",
      "03112021 09:58:33|INFO|allennlp.training.trainer| Epoch duration: 0:03:04.212215\n",
      "03112021 09:58:33|INFO|allennlp.training.trainer| Estimated training time remaining: 0:23:44\n",
      "03112021 09:58:33|INFO|allennlp.training.trainer| Epoch 2/9\n",
      "03112021 09:58:33|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5634.928\n",
      "03112021 09:58:34|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 16710\n",
      "03112021 09:58:34|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03112021 09:58:34|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 16710\n",
      "03112021 09:58:34|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03112021 09:58:34|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc4cc3cda4c41a697c235b79b638915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=242.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 10:00:44|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6e8ff0f4f84923b64b77910ca8b451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 10:01:24|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03112021 10:01:24|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.871  |     0.703\n",
      "03112021 10:01:24|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  16710.000  |       N/A\n",
      "03112021 10:01:24|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03112021 10:01:24|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  16710.000  |       N/A\n",
      "03112021 10:01:24|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03112021 10:01:24|INFO|allennlp.training.tensorboard_writer| loss               |     0.445  |     1.036\n",
      "03112021 10:01:24|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03112021 10:01:24|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5634.928  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 10:01:27|INFO|allennlp.training.checkpointer| Best validation performance so far. Copying weights to '/home/mlepekhin/models/rubert_enru_attacked_30/checkpoints/best.th'.\n",
      "03112021 10:01:34|INFO|allennlp.training.trainer| Epoch duration: 0:03:01.043051\n",
      "03112021 10:01:34|INFO|allennlp.training.trainer| Estimated training time remaining: 0:20:53\n",
      "03112021 10:01:34|INFO|allennlp.training.trainer| Epoch 3/9\n",
      "03112021 10:01:34|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5634.928\n",
      "03112021 10:01:35|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 16710\n",
      "03112021 10:01:35|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03112021 10:01:35|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 16710\n",
      "03112021 10:01:35|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03112021 10:01:35|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76856a71afbd460cab163347db9cc639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=242.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 10:03:45|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33f91bb775445e5ac59265da6051bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 10:04:25|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03112021 10:04:25|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.926  |     0.669\n",
      "03112021 10:04:25|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  16710.000  |       N/A\n",
      "03112021 10:04:25|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03112021 10:04:25|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  16710.000  |       N/A\n",
      "03112021 10:04:25|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03112021 10:04:25|INFO|allennlp.training.tensorboard_writer| loss               |     0.261  |     1.280\n",
      "03112021 10:04:25|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03112021 10:04:25|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5634.928  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 10:04:28|INFO|allennlp.training.trainer| Epoch duration: 0:02:53.257298\n",
      "03112021 10:04:28|INFO|allennlp.training.trainer| Estimated training time remaining: 0:17:45\n",
      "03112021 10:04:28|INFO|allennlp.training.trainer| Epoch 4/9\n",
      "03112021 10:04:28|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5634.928\n",
      "03112021 10:04:28|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 16710\n",
      "03112021 10:04:28|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03112021 10:04:28|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 16710\n",
      "03112021 10:04:28|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03112021 10:04:28|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8539ed787c487ea4f10bd6d0580f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=242.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 10:06:38|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910e53ceff2f476b9e1d2c0ce179b47c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 10:07:19|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03112021 10:07:19|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.935  |     0.695\n",
      "03112021 10:07:19|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  16710.000  |       N/A\n",
      "03112021 10:07:19|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03112021 10:07:19|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  16710.000  |       N/A\n",
      "03112021 10:07:19|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03112021 10:07:19|INFO|allennlp.training.tensorboard_writer| loss               |     0.216  |     1.260\n",
      "03112021 10:07:19|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03112021 10:07:19|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5634.928  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 10:07:21|INFO|allennlp.training.trainer| Epoch duration: 0:02:53.687091\n",
      "03112021 10:07:21|INFO|allennlp.training.trainer| Estimated training time remaining: 0:14:43\n",
      "03112021 10:07:21|INFO|allennlp.training.trainer| Epoch 5/9\n",
      "03112021 10:07:21|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5634.928\n",
      "03112021 10:07:22|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 16710\n",
      "03112021 10:07:22|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03112021 10:07:22|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 16710\n",
      "03112021 10:07:22|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03112021 10:07:22|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b6dfea339e453b9108e3b476a38dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=242.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 10:09:32|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b971b8f4d8d642cca8d38c6158babc30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 10:10:12|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03112021 10:10:12|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.969  |     0.713\n",
      "03112021 10:10:12|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  16710.000  |       N/A\n",
      "03112021 10:10:12|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03112021 10:10:12|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  16710.000  |       N/A\n",
      "03112021 10:10:12|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03112021 10:10:12|INFO|allennlp.training.tensorboard_writer| loss               |     0.119  |     1.275\n",
      "03112021 10:10:12|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03112021 10:10:12|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5634.928  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 10:10:15|INFO|allennlp.training.checkpointer| Best validation performance so far. Copying weights to '/home/mlepekhin/models/rubert_enru_attacked_30/checkpoints/best.th'.\n",
      "03112021 10:10:25|INFO|allennlp.training.trainer| Epoch duration: 0:03:03.256317\n",
      "03112021 10:10:25|INFO|allennlp.training.trainer| Estimated training time remaining: 0:11:51\n",
      "03112021 10:10:25|INFO|allennlp.training.trainer| Epoch 6/9\n",
      "03112021 10:10:25|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5634.928\n",
      "03112021 10:10:25|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 16710\n",
      "03112021 10:10:25|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03112021 10:10:25|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 16710\n",
      "03112021 10:10:25|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03112021 10:10:25|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b72fcd93f8d4a7f82655d0cfd569173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=242.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 10:12:35|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ecdc09a1d74a6abfb3c50a576c220a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 10:13:15|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03112021 10:13:15|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.975  |     0.717\n",
      "03112021 10:13:15|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  16710.000  |       N/A\n",
      "03112021 10:13:15|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03112021 10:13:15|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  16710.000  |       N/A\n",
      "03112021 10:13:15|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03112021 10:13:15|INFO|allennlp.training.tensorboard_writer| loss               |     0.098  |     1.365\n",
      "03112021 10:13:15|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03112021 10:13:15|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5634.928  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 10:13:18|INFO|allennlp.training.checkpointer| Best validation performance so far. Copying weights to '/home/mlepekhin/models/rubert_enru_attacked_30/checkpoints/best.th'.\n",
      "03112021 10:13:23|INFO|allennlp.training.trainer| Epoch duration: 0:02:58.163258\n",
      "03112021 10:13:23|INFO|allennlp.training.trainer| Estimated training time remaining: 0:08:53\n",
      "03112021 10:13:23|INFO|allennlp.training.trainer| Epoch 7/9\n",
      "03112021 10:13:23|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5634.928\n",
      "03112021 10:13:23|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 16710\n",
      "03112021 10:13:23|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03112021 10:13:23|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 16710\n",
      "03112021 10:13:23|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03112021 10:13:23|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4273352690ca498f86646c7aad96ad55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=242.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 10:15:33|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521bd69cc2e5497d9a6c3c6e6e01501e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 10:16:14|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03112021 10:16:14|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.990  |     0.704\n",
      "03112021 10:16:14|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  16710.000  |       N/A\n",
      "03112021 10:16:14|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03112021 10:16:14|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  16710.000  |       N/A\n",
      "03112021 10:16:14|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03112021 10:16:14|INFO|allennlp.training.tensorboard_writer| loss               |     0.046  |     1.509\n",
      "03112021 10:16:14|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03112021 10:16:14|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5634.928  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 10:16:16|INFO|allennlp.training.trainer| Epoch duration: 0:02:53.376342\n",
      "03112021 10:16:16|INFO|allennlp.training.trainer| Estimated training time remaining: 0:05:54\n",
      "03112021 10:16:16|INFO|allennlp.training.trainer| Epoch 8/9\n",
      "03112021 10:16:16|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5634.928\n",
      "03112021 10:16:16|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 16710\n",
      "03112021 10:16:16|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03112021 10:16:16|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 16710\n",
      "03112021 10:16:16|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03112021 10:16:16|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db2cfee6bb3e4e10b20db40b5fa5784e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=242.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 10:18:27|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645a173cefae4f01a65ee079d6d09e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 10:19:07|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03112021 10:19:07|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.984  |     0.676\n",
      "03112021 10:19:07|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  16710.000  |       N/A\n",
      "03112021 10:19:07|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03112021 10:19:07|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  16710.000  |       N/A\n",
      "03112021 10:19:07|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03112021 10:19:07|INFO|allennlp.training.tensorboard_writer| loss               |     0.056  |     1.730\n",
      "03112021 10:19:07|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03112021 10:19:07|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5634.928  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 10:19:10|INFO|allennlp.training.trainer| Epoch duration: 0:02:53.446126\n",
      "03112021 10:19:10|INFO|allennlp.training.trainer| Estimated training time remaining: 0:02:56\n",
      "03112021 10:19:10|INFO|allennlp.training.trainer| Epoch 9/9\n",
      "03112021 10:19:10|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5634.928\n",
      "03112021 10:19:10|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 16710\n",
      "03112021 10:19:10|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03112021 10:19:10|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 16710\n",
      "03112021 10:19:10|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03112021 10:19:10|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccdd96775c9b4d3985bd751fee518517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=242.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 10:21:20|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef3d1460cc94aaa8638513ba6d7d7cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 10:22:01|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03112021 10:22:01|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.986  |     0.715\n",
      "03112021 10:22:01|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  16710.000  |       N/A\n",
      "03112021 10:22:01|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03112021 10:22:01|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  16710.000  |       N/A\n",
      "03112021 10:22:01|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03112021 10:22:01|INFO|allennlp.training.tensorboard_writer| loss               |     0.052  |     1.524\n",
      "03112021 10:22:01|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03112021 10:22:01|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5634.928  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 10:22:04|INFO|allennlp.training.trainer| Epoch duration: 0:02:53.980735\n",
      "03112021 10:22:04|INFO|allennlp.training.checkpointer| loading best weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "train_loader, dev_loader = build_data_loaders(train_data, dev_data)\n",
    "\n",
    "# You obviously won't want to create a temporary file for your training\n",
    "# results, but for execution in binder for this course, we need to do this.\n",
    "\n",
    "trainer = build_classifier_trainer(\n",
    "    model,\n",
    "    pathjoin(MODELS_DIR, MODEL_ID, 'checkpoints'),\n",
    "    train_loader,\n",
    "    dev_loader,\n",
    "    10,\n",
    "    cuda_device=cuda_device\n",
    ")\n",
    "print(\"Starting training\")\n",
    "trainer.train()\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03112021 10:22:05|INFO|filelock| Lock 139703314786288 acquired on /home/mlepekhin/models/rubert_enru_attacked_30/vocab/.lock\n",
      "03112021 10:22:05|INFO|filelock| Lock 139703314786288 released on /home/mlepekhin/models/rubert_enru_attacked_30/vocab/.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 681M\r\n",
      "-rw-rw-r-- 1 mlepekhin mlepekhin 681M мар 11 10:13 best.th\r\n",
      "drwxrwxr-x 4 mlepekhin mlepekhin 4,0K мар 11 09:52 log\r\n"
     ]
    }
   ],
   "source": [
    "!rm \"{CHECKPOINTS_DIR}\"/*.json \"{CHECKPOINTS_DIR}\"/model* \"{CHECKPOINTS_DIR}\"/training*\n",
    "model.vocab.save_to_files(pathjoin(MODELS_DIR, MODEL_ID, 'vocab'))\n",
    "!ls -lh \"{CHECKPOINTS_DIR}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
