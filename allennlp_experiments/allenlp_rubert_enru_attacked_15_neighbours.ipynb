{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mseven              \u001b[m  Wed Mar 10 18:02:48 2021  \u001b[1m\u001b[30m440.64\u001b[m\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mTITAN RTX       \u001b[m |\u001b[31m 34'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   11\u001b[m / \u001b[33m24220\u001b[m MB |\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mTITAN RTX       \u001b[m |\u001b[1m\u001b[31m 71'C\u001b[m, \u001b[1m\u001b[32m 37 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 2662\u001b[m / \u001b[33m24220\u001b[m MB | \u001b[1m\u001b[30mcwb\u001b[m(\u001b[33m2651M\u001b[m)\r\n",
      "\u001b[36m[2]\u001b[m \u001b[34mTITAN RTX       \u001b[m |\u001b[31m 32'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   11\u001b[m / \u001b[33m24220\u001b[m MB |\r\n",
      "\u001b[36m[3]\u001b[m \u001b[34mTITAN RTX       \u001b[m |\u001b[1m\u001b[31m 86'C\u001b[m, \u001b[1m\u001b[32m 98 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 9928\u001b[m / \u001b[33m24220\u001b[m MB | \u001b[1m\u001b[30mcwb\u001b[m(\u001b[33m3411M\u001b[m) \u001b[1m\u001b[30mcwb\u001b[m(\u001b[33m3063M\u001b[m) \u001b[1m\u001b[30mcwb\u001b[m(\u001b[33m3443M\u001b[m)\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as pathjoin\n",
    "from data_processing import *\n",
    "from interpretation import *\n",
    "from models import *\n",
    "from training import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3813, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>changed_words_num</th>\n",
       "      <th>new_model_target</th>\n",
       "      <th>old_model_target</th>\n",
       "      <th>old_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>579</td>\n",
       "      <td>A12</td>\n",
       "      <td>ФИБРЕСИР ( FIBRECIRE ) - Довольно эффектный те...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>A17</td>\n",
       "      <td>A12</td>\n",
       "      <td>ФИБРЕСИР ( FIBRECIRE ) - Чрезвычайно эффектный...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>342</td>\n",
       "      <td>A8</td>\n",
       "      <td>Сноуден тайком от США попросил убежища еще в ш...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>A1</td>\n",
       "      <td>A8</td>\n",
       "      <td>Сноуден тайком от США попросил убежища еще в ш...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>1043</td>\n",
       "      <td>A11</td>\n",
       "      <td>&lt;p&gt; На третьей неделе заданием были игры с акв...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>808</td>\n",
       "      <td>A16</td>\n",
       "      <td>Wind energy is abundant , inexhaustible , wide...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>143</td>\n",
       "      <td>A1</td>\n",
       "      <td>Бензин должен стоить 20 рублей , объявил Игорь...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 target                                               text  \\\n",
       "579          579    A12  ФИБРЕСИР ( FIBRECIRE ) - Довольно эффектный те...   \n",
       "342          342     A8  Сноуден тайком от США попросил убежища еще в ш...   \n",
       "599         1043    A11  <p> На третьей неделе заданием были игры с акв...   \n",
       "774          808    A16  Wind energy is abundant , inexhaustible , wide...   \n",
       "1161         143     A1  Бензин должен стоить 20 рублей , объявил Игорь...   \n",
       "\n",
       "      changed_words_num new_model_target old_model_target  \\\n",
       "579                19.0              A17              A12   \n",
       "342                20.0               A1               A8   \n",
       "599                 NaN              NaN              NaN   \n",
       "774                 NaN              NaN              NaN   \n",
       "1161                NaN              NaN              NaN   \n",
       "\n",
       "                                               old_text  \n",
       "579   ФИБРЕСИР ( FIBRECIRE ) - Чрезвычайно эффектный...  \n",
       "342   Сноуден тайком от США попросил убежища еще в ш...  \n",
       "599                                                 NaN  \n",
       "774                                                 NaN  \n",
       "1161                                                NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddd = pd.read_csv('/home/mlepekhin/data/ru_train')\n",
    "ddd = ddd.append(pd.read_csv('/home/mlepekhin/data/en_train'))\n",
    "ddd = ddd.append(pd.read_csv('/home/mlepekhin/data/new_ru_attacked.csv'))\n",
    "ddd = ddd.append(pd.read_csv('/home/mlepekhin/data/en_attacked.csv')).sample(frac=1, random_state=42)\n",
    "print(ddd.shape)\n",
    "ddd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddd.to_csv('enru_attacked_train_15.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/mlepekhin/data'\n",
    "MODELS_DIR = '/home/mlepekhin/models'\n",
    "MODEL_ID = 'rubert_enru_attacked_15' \n",
    "CHECKPOINTS_DIR = pathjoin(MODELS_DIR, MODEL_ID, 'checkpoints')\n",
    "BEST_MODEL = pathjoin(CHECKPOINTS_DIR, 'best.th')Mon film préféréMon film préféréMon film préféréMon film préféré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = 'DeepPavlov/rubert-base-cased'\n",
    "MAX_TOKENS = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:29:35|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03102021 22:29:35|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "03102021 22:29:35|INFO|transformers.tokenization_utils| Model name 'DeepPavlov/rubert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'DeepPavlov/rubert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03102021 22:29:37|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/vocab.txt from cache at /home/mlepekhin/.cache/torch/transformers/3e164bb7396e401202e250721569fb407583681bb6ea0c34f431af622435a3d8.67d40fedd426f94e9ea8d75f879bbc353613af6b908324e8eca582d4cfa9b0eb\n",
      "03102021 22:29:37|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/added_tokens.json from cache at None\n",
      "03102021 22:29:37|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/special_tokens_map.json from cache at /home/mlepekhin/.cache/torch/transformers/d44047cea679f35c9ce4f09172821fc62d3b493f77e63d3aeffd42f51df90ce9.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "03102021 22:29:37|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/tokenizer_config.json from cache at /home/mlepekhin/.cache/torch/transformers/1db6339329fc47780d55cc00813fef2f7a1e4b802ec31509975c82b8a7d74e4e.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n",
      "03102021 22:29:37|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03102021 22:29:37|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "03102021 22:29:37|INFO|transformers.tokenization_utils| Model name 'DeepPavlov/rubert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'DeepPavlov/rubert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03102021 22:29:40|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/vocab.txt from cache at /home/mlepekhin/.cache/torch/transformers/3e164bb7396e401202e250721569fb407583681bb6ea0c34f431af622435a3d8.67d40fedd426f94e9ea8d75f879bbc353613af6b908324e8eca582d4cfa9b0eb\n",
      "03102021 22:29:40|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/added_tokens.json from cache at None\n",
      "03102021 22:29:40|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/special_tokens_map.json from cache at /home/mlepekhin/.cache/torch/transformers/d44047cea679f35c9ce4f09172821fc62d3b493f77e63d3aeffd42f51df90ce9.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "03102021 22:29:40|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/tokenizer_config.json from cache at /home/mlepekhin/.cache/torch/transformers/1db6339329fc47780d55cc00813fef2f7a1e4b802ec31509975c82b8a7d74e4e.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n"
     ]
    }
   ],
   "source": [
    "tokenizer = PretrainedTransformerTokenizer(transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:29:40|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03102021 22:29:40|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "03102021 22:29:40|INFO|transformers.tokenization_utils| Model name 'DeepPavlov/rubert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'DeepPavlov/rubert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03102021 22:29:43|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/vocab.txt from cache at /home/mlepekhin/.cache/torch/transformers/3e164bb7396e401202e250721569fb407583681bb6ea0c34f431af622435a3d8.67d40fedd426f94e9ea8d75f879bbc353613af6b908324e8eca582d4cfa9b0eb\n",
      "03102021 22:29:43|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/added_tokens.json from cache at None\n",
      "03102021 22:29:43|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/special_tokens_map.json from cache at /home/mlepekhin/.cache/torch/transformers/d44047cea679f35c9ce4f09172821fc62d3b493f77e63d3aeffd42f51df90ce9.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "03102021 22:29:43|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/tokenizer_config.json from cache at /home/mlepekhin/.cache/torch/transformers/1db6339329fc47780d55cc00813fef2f7a1e4b802ec31509975c82b8a7d74e4e.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n",
      "03102021 22:29:43|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03102021 22:29:43|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "03102021 22:29:43|INFO|transformers.tokenization_utils| Model name 'DeepPavlov/rubert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'DeepPavlov/rubert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03102021 22:29:45|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/vocab.txt from cache at /home/mlepekhin/.cache/torch/transformers/3e164bb7396e401202e250721569fb407583681bb6ea0c34f431af622435a3d8.67d40fedd426f94e9ea8d75f879bbc353613af6b908324e8eca582d4cfa9b0eb\n",
      "03102021 22:29:45|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/added_tokens.json from cache at None\n",
      "03102021 22:29:45|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/special_tokens_map.json from cache at /home/mlepekhin/.cache/torch/transformers/d44047cea679f35c9ce4f09172821fc62d3b493f77e63d3aeffd42f51df90ce9.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "03102021 22:29:45|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/tokenizer_config.json from cache at /home/mlepekhin/.cache/torch/transformers/1db6339329fc47780d55cc00813fef2f7a1e4b802ec31509975c82b8a7d74e4e.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n",
      "03102021 22:29:46|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03102021 22:29:46|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "03102021 22:29:46|INFO|transformers.tokenization_utils| Model name 'DeepPavlov/rubert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'DeepPavlov/rubert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:29:48|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/vocab.txt from cache at /home/mlepekhin/.cache/torch/transformers/3e164bb7396e401202e250721569fb407583681bb6ea0c34f431af622435a3d8.67d40fedd426f94e9ea8d75f879bbc353613af6b908324e8eca582d4cfa9b0eb\n",
      "03102021 22:29:48|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/added_tokens.json from cache at None\n",
      "03102021 22:29:48|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/special_tokens_map.json from cache at /home/mlepekhin/.cache/torch/transformers/d44047cea679f35c9ce4f09172821fc62d3b493f77e63d3aeffd42f51df90ce9.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "03102021 22:29:48|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/tokenizer_config.json from cache at /home/mlepekhin/.cache/torch/transformers/1db6339329fc47780d55cc00813fef2f7a1e4b802ec31509975c82b8a7d74e4e.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n",
      "03102021 22:29:49|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03102021 22:29:49|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "03102021 22:29:49|INFO|transformers.tokenization_utils| Model name 'DeepPavlov/rubert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'DeepPavlov/rubert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03102021 22:29:56|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/vocab.txt from cache at /home/mlepekhin/.cache/torch/transformers/3e164bb7396e401202e250721569fb407583681bb6ea0c34f431af622435a3d8.67d40fedd426f94e9ea8d75f879bbc353613af6b908324e8eca582d4cfa9b0eb\n",
      "03102021 22:29:56|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/added_tokens.json from cache at None\n",
      "03102021 22:29:56|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/special_tokens_map.json from cache at /home/mlepekhin/.cache/torch/transformers/d44047cea679f35c9ce4f09172821fc62d3b493f77e63d3aeffd42f51df90ce9.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "03102021 22:29:56|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/tokenizer_config.json from cache at /home/mlepekhin/.cache/torch/transformers/1db6339329fc47780d55cc00813fef2f7a1e4b802ec31509975c82b8a7d74e4e.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n",
      "03102021 22:29:57|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03102021 22:29:57|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "03102021 22:29:57|INFO|transformers.tokenization_utils| Model name 'DeepPavlov/rubert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'DeepPavlov/rubert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03102021 22:29:59|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/vocab.txt from cache at /home/mlepekhin/.cache/torch/transformers/3e164bb7396e401202e250721569fb407583681bb6ea0c34f431af622435a3d8.67d40fedd426f94e9ea8d75f879bbc353613af6b908324e8eca582d4cfa9b0eb\n",
      "03102021 22:29:59|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/added_tokens.json from cache at None\n",
      "03102021 22:29:59|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/special_tokens_map.json from cache at /home/mlepekhin/.cache/torch/transformers/d44047cea679f35c9ce4f09172821fc62d3b493f77e63d3aeffd42f51df90ce9.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "03102021 22:29:59|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/tokenizer_config.json from cache at /home/mlepekhin/.cache/torch/transformers/1db6339329fc47780d55cc00813fef2f7a1e4b802ec31509975c82b8a7d74e4e.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n",
      "03102021 22:29:59|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03102021 22:29:59|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:29:59|INFO|transformers.tokenization_utils| Model name 'DeepPavlov/rubert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'DeepPavlov/rubert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03102021 22:30:02|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/vocab.txt from cache at /home/mlepekhin/.cache/torch/transformers/3e164bb7396e401202e250721569fb407583681bb6ea0c34f431af622435a3d8.67d40fedd426f94e9ea8d75f879bbc353613af6b908324e8eca582d4cfa9b0eb\n",
      "03102021 22:30:02|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/added_tokens.json from cache at None\n",
      "03102021 22:30:02|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/special_tokens_map.json from cache at /home/mlepekhin/.cache/torch/transformers/d44047cea679f35c9ce4f09172821fc62d3b493f77e63d3aeffd42f51df90ce9.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "03102021 22:30:02|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/tokenizer_config.json from cache at /home/mlepekhin/.cache/torch/transformers/1db6339329fc47780d55cc00813fef2f7a1e4b802ec31509975c82b8a7d74e4e.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n",
      "03102021 22:30:02|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03102021 22:30:02|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "03102021 22:30:02|INFO|transformers.tokenization_utils| Model name 'DeepPavlov/rubert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'DeepPavlov/rubert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03102021 22:30:04|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/vocab.txt from cache at /home/mlepekhin/.cache/torch/transformers/3e164bb7396e401202e250721569fb407583681bb6ea0c34f431af622435a3d8.67d40fedd426f94e9ea8d75f879bbc353613af6b908324e8eca582d4cfa9b0eb\n",
      "03102021 22:30:04|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/added_tokens.json from cache at None\n",
      "03102021 22:30:04|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/special_tokens_map.json from cache at /home/mlepekhin/.cache/torch/transformers/d44047cea679f35c9ce4f09172821fc62d3b493f77e63d3aeffd42f51df90ce9.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "03102021 22:30:04|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/tokenizer_config.json from cache at /home/mlepekhin/.cache/torch/transformers/1db6339329fc47780d55cc00813fef2f7a1e4b802ec31509975c82b8a7d74e4e.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n",
      "03102021 22:30:05|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03102021 22:30:05|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "03102021 22:30:05|INFO|transformers.tokenization_utils| Model name 'DeepPavlov/rubert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'DeepPavlov/rubert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03102021 22:30:07|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/vocab.txt from cache at /home/mlepekhin/.cache/torch/transformers/3e164bb7396e401202e250721569fb407583681bb6ea0c34f431af622435a3d8.67d40fedd426f94e9ea8d75f879bbc353613af6b908324e8eca582d4cfa9b0eb\n",
      "03102021 22:30:07|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/added_tokens.json from cache at None\n",
      "03102021 22:30:07|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/special_tokens_map.json from cache at /home/mlepekhin/.cache/torch/transformers/d44047cea679f35c9ce4f09172821fc62d3b493f77e63d3aeffd42f51df90ce9.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "03102021 22:30:07|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/tokenizer_config.json from cache at /home/mlepekhin/.cache/torch/transformers/1db6339329fc47780d55cc00813fef2f7a1e4b802ec31509975c82b8a7d74e4e.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n",
      "<class 'data_processing.ClassificationDatasetReader'> enru_attacked_train_15.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30b617c782e4fc781081615ffd0c7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1f0419d1b54164a2fc14aa6ce798ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:31:58|INFO|allennlp.data.vocabulary| Fitting token dictionary from dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building the vocabulary\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc1a35e20baf4b5ebdcee1eee197073e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7366.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset_reader = build_transformer_dataset_reader(transformer_model, lower=True)\n",
    "val_dataset_reader = build_transformer_dataset_reader(transformer_model, lower=True)\n",
    "\n",
    "train_data, dev_data = read_data(\n",
    "    \"enru_attacked_train_15.csv\", \n",
    "    pathjoin(DATA_DIR, \"manual_genres\", \"all.csv\"),\n",
    "    train_dataset_reader, \n",
    "    val_dataset_reader\n",
    ")\n",
    "\n",
    "vocab = build_vocab(train_data + dev_data)\n",
    "\n",
    "train_data.index_with(vocab)\n",
    "dev_data.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:31:58|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03102021 22:31:58|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "03102021 22:31:59|INFO|transformers.modeling_utils| loading weights file https://cdn.huggingface.co/DeepPavlov/rubert-base-cased/pytorch_model.bin from cache at /home/mlepekhin/.cache/torch/transformers/611b8e3ce80c0751b16e01b0e7c133fffc388089408bb9ef7f8a2d60c9758fd3.71d8ad10edfcd7c68264ea03bc1b14e1f7b9c67affdfe8d6f96e1a6ce2c136ee\n",
      "03102021 22:32:05|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03102021 22:32:05|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "03102021 22:32:05|INFO|transformers.tokenization_utils| Model name 'DeepPavlov/rubert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'DeepPavlov/rubert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03102021 22:32:07|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/vocab.txt from cache at /home/mlepekhin/.cache/torch/transformers/3e164bb7396e401202e250721569fb407583681bb6ea0c34f431af622435a3d8.67d40fedd426f94e9ea8d75f879bbc353613af6b908324e8eca582d4cfa9b0eb\n",
      "03102021 22:32:07|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/added_tokens.json from cache at None\n",
      "03102021 22:32:07|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/special_tokens_map.json from cache at /home/mlepekhin/.cache/torch/transformers/d44047cea679f35c9ce4f09172821fc62d3b493f77e63d3aeffd42f51df90ce9.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "03102021 22:32:07|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/tokenizer_config.json from cache at /home/mlepekhin/.cache/torch/transformers/1db6339329fc47780d55cc00813fef2f7a1e4b802ec31509975c82b8a7d74e4e.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n",
      "03102021 22:32:08|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03102021 22:32:08|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "03102021 22:32:08|INFO|transformers.tokenization_utils| Model name 'DeepPavlov/rubert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'DeepPavlov/rubert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "03102021 22:32:10|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/vocab.txt from cache at /home/mlepekhin/.cache/torch/transformers/3e164bb7396e401202e250721569fb407583681bb6ea0c34f431af622435a3d8.67d40fedd426f94e9ea8d75f879bbc353613af6b908324e8eca582d4cfa9b0eb\n",
      "03102021 22:32:10|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/added_tokens.json from cache at None\n",
      "03102021 22:32:10|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/special_tokens_map.json from cache at /home/mlepekhin/.cache/torch/transformers/d44047cea679f35c9ce4f09172821fc62d3b493f77e63d3aeffd42f51df90ce9.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "03102021 22:32:10|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/tokenizer_config.json from cache at /home/mlepekhin/.cache/torch/transformers/1db6339329fc47780d55cc00813fef2f7a1e4b802ec31509975c82b8a7d74e4e.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n",
      "03102021 22:32:11|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/DeepPavlov/rubert-base-cased/config.json from cache at /home/mlepekhin/.cache/torch/transformers/b1ea51df212fa070e3a8a7d04dedb4800621e5a5bf504ecdb305faa622b46aa0.41d1cb30da8abef9028a44a17bd9c152daca0bd46e409bc271f324a28d109450\n",
      "03102021 22:32:11|INFO|transformers.configuration_utils| Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:32:11|INFO|transformers.modeling_utils| loading weights file https://cdn.huggingface.co/DeepPavlov/rubert-base-cased/pytorch_model.bin from cache at /home/mlepekhin/.cache/torch/transformers/611b8e3ce80c0751b16e01b0e7c133fffc388089408bb9ef7f8a2d60c9758fd3.71d8ad10edfcd7c68264ea03bc1b14e1f7b9c67affdfe8d6f96e1a6ce2c136ee\n"
     ]
    }
   ],
   "source": [
    "model = build_transformer_model(vocab, transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    cuda_device = 0\n",
    "    model = model.cuda(cuda_device)\n",
    "else:\n",
    "    cuda_device = -1\n",
    "print(cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {CHECKPOINTS_DIR}\n",
    "!mkdir -p {CHECKPOINTS_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:32:18|INFO|allennlp.training.optimizers| Number of trainable parameters: 178452491\n",
      "03102021 22:32:18|WARNING|allennlp.training.trainer| You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n",
      "03102021 22:32:18|INFO|allennlp.training.trainer| Beginning training.\n",
      "03102021 22:32:18|INFO|allennlp.training.trainer| Epoch 0/9\n",
      "03102021 22:32:18|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 4946.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:32:18|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 1608\n",
      "03102021 22:32:18|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03102021 22:32:18|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 11\n",
      "03102021 22:32:18|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03102021 22:32:18|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd3b848c4624ab3aa62614c12cee8f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=239.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:34:27|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe6a4dbb24a483d80cb9211233d3dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:35:10|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03102021 22:35:10|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.594  |     0.665\n",
      "03102021 22:35:10|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  1608.000  |       N/A\n",
      "03102021 22:35:10|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03102021 22:35:10|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |    11.000  |       N/A\n",
      "03102021 22:35:10|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03102021 22:35:10|INFO|allennlp.training.tensorboard_writer| loss               |     1.313  |     1.011\n",
      "03102021 22:35:10|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03102021 22:35:10|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  4946.960  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:35:12|INFO|allennlp.training.checkpointer| Best validation performance so far. Copying weights to '/home/mlepekhin/models/rubert_enru_attacked_15/checkpoints/best.th'.\n",
      "03102021 22:35:12|INFO|allennlp.training.trainer| Epoch duration: 0:02:54.308859\n",
      "03102021 22:35:12|INFO|allennlp.training.trainer| Estimated training time remaining: 0:26:08\n",
      "03102021 22:35:12|INFO|allennlp.training.trainer| Epoch 1/9\n",
      "03102021 22:35:12|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 4995.736\n",
      "03102021 22:35:13|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 16710\n",
      "03102021 22:35:13|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03102021 22:35:13|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 11\n",
      "03102021 22:35:13|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03102021 22:35:13|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d61dd65adef49b0a6bc2f32ea9f1a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=239.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:37:37|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac638057d704e3facfabe617c8c2b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:38:24|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03102021 22:38:24|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.794  |     0.710\n",
      "03102021 22:38:24|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  16710.000  |       N/A\n",
      "03102021 22:38:24|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03102021 22:38:24|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |    11.000  |       N/A\n",
      "03102021 22:38:24|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03102021 22:38:24|INFO|allennlp.training.tensorboard_writer| loss               |     0.666  |     0.940\n",
      "03102021 22:38:24|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03102021 22:38:24|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  4995.736  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:38:26|INFO|allennlp.training.checkpointer| Best validation performance so far. Copying weights to '/home/mlepekhin/models/rubert_enru_attacked_15/checkpoints/best.th'.\n",
      "03102021 22:38:31|INFO|allennlp.training.trainer| Epoch duration: 0:03:18.244616\n",
      "03102021 22:38:31|INFO|allennlp.training.trainer| Estimated training time remaining: 0:24:50\n",
      "03102021 22:38:31|INFO|allennlp.training.trainer| Epoch 2/9\n",
      "03102021 22:38:31|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 4995.976\n",
      "03102021 22:38:31|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 16710\n",
      "03102021 22:38:31|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03102021 22:38:31|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 11\n",
      "03102021 22:38:31|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03102021 22:38:31|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3961c3b6744c4ebb91122ee70e275967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=239.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:40:58|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb723eb52da45da92cb878479dd4cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:41:45|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03102021 22:41:45|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.877  |     0.684\n",
      "03102021 22:41:45|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  16710.000  |       N/A\n",
      "03102021 22:41:45|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03102021 22:41:45|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |    11.000  |       N/A\n",
      "03102021 22:41:45|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03102021 22:41:45|INFO|allennlp.training.tensorboard_writer| loss               |     0.420  |     1.081\n",
      "03102021 22:41:45|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03102021 22:41:45|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  4995.976  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:41:47|INFO|allennlp.training.trainer| Epoch duration: 0:03:16.672466\n",
      "03102021 22:41:47|INFO|allennlp.training.trainer| Estimated training time remaining: 0:22:08\n",
      "03102021 22:41:47|INFO|allennlp.training.trainer| Epoch 3/9\n",
      "03102021 22:41:47|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 4995.98\n",
      "03102021 22:41:48|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 16710\n",
      "03102021 22:41:48|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03102021 22:41:48|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 11\n",
      "03102021 22:41:48|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03102021 22:41:48|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa953166fc844723bf94204ee05704dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=239.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:44:16|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e9db22608a4408b55139623e8d8fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:45:03|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03102021 22:45:03|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.936  |     0.710\n",
      "03102021 22:45:03|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  16710.000  |       N/A\n",
      "03102021 22:45:03|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03102021 22:45:03|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |    11.000  |       N/A\n",
      "03102021 22:45:03|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03102021 22:45:03|INFO|allennlp.training.tensorboard_writer| loss               |     0.237  |     1.076\n",
      "03102021 22:45:03|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03102021 22:45:03|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  4995.980  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:45:06|INFO|allennlp.training.trainer| Epoch duration: 0:03:18.229436\n",
      "03102021 22:45:06|INFO|allennlp.training.trainer| Estimated training time remaining: 0:19:11\n",
      "03102021 22:45:06|INFO|allennlp.training.trainer| Epoch 4/9\n",
      "03102021 22:45:06|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 4996.18\n",
      "03102021 22:45:06|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 16710\n",
      "03102021 22:45:06|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03102021 22:45:06|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 11\n",
      "03102021 22:45:06|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03102021 22:45:06|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8fd13e28ee4fd08dbb3ab62a9bdb68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=239.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:47:35|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bcd7377772c446d83f6671cc4e1a725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:48:22|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03102021 22:48:22|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.953  |     0.722\n",
      "03102021 22:48:22|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  16710.000  |       N/A\n",
      "03102021 22:48:22|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03102021 22:48:22|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |    11.000  |       N/A\n",
      "03102021 22:48:22|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03102021 22:48:22|INFO|allennlp.training.tensorboard_writer| loss               |     0.165  |     1.121\n",
      "03102021 22:48:22|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03102021 22:48:22|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  4996.180  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:48:24|INFO|allennlp.training.checkpointer| Best validation performance so far. Copying weights to '/home/mlepekhin/models/rubert_enru_attacked_15/checkpoints/best.th'.\n",
      "03102021 22:48:29|INFO|allennlp.training.trainer| Epoch duration: 0:03:23.296777\n",
      "03102021 22:48:29|INFO|allennlp.training.trainer| Estimated training time remaining: 0:16:10\n",
      "03102021 22:48:29|INFO|allennlp.training.trainer| Epoch 5/9\n",
      "03102021 22:48:29|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 4996.18\n",
      "03102021 22:48:29|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 16710\n",
      "03102021 22:48:29|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03102021 22:48:29|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 11\n",
      "03102021 22:48:29|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03102021 22:48:29|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33bba47002d4c4198ce144725143066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=239.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:50:56|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d31e72723f184d6c832b5935234854a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:51:43|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03102021 22:51:43|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.968  |     0.714\n",
      "03102021 22:51:43|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  16710.000  |       N/A\n",
      "03102021 22:51:43|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03102021 22:51:43|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |    11.000  |       N/A\n",
      "03102021 22:51:43|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03102021 22:51:43|INFO|allennlp.training.tensorboard_writer| loss               |     0.106  |     1.312\n",
      "03102021 22:51:43|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03102021 22:51:44|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  4996.180  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:51:46|INFO|allennlp.training.trainer| Epoch duration: 0:03:16.950483\n",
      "03102021 22:51:46|INFO|allennlp.training.trainer| Estimated training time remaining: 0:12:58\n",
      "03102021 22:51:46|INFO|allennlp.training.trainer| Epoch 6/9\n",
      "03102021 22:51:46|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 4996.184\n",
      "03102021 22:51:46|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 16710\n",
      "03102021 22:51:46|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03102021 22:51:46|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 11\n",
      "03102021 22:51:46|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03102021 22:51:46|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f209c929154fc88e96736d3fb6dd1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=239.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:54:15|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "045ebc44dc0c4f5d9d1df6786047206b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:55:02|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03102021 22:55:02|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.974  |     0.705\n",
      "03102021 22:55:02|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  16710.000  |       N/A\n",
      "03102021 22:55:02|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03102021 22:55:02|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |    11.000  |       N/A\n",
      "03102021 22:55:02|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03102021 22:55:02|INFO|allennlp.training.tensorboard_writer| loss               |     0.095  |     1.424\n",
      "03102021 22:55:02|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03102021 22:55:02|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  4996.184  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:55:04|INFO|allennlp.training.trainer| Epoch duration: 0:03:18.184147\n",
      "03102021 22:55:04|INFO|allennlp.training.trainer| Estimated training time remaining: 0:09:45\n",
      "03102021 22:55:04|INFO|allennlp.training.trainer| Epoch 7/9\n",
      "03102021 22:55:04|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 4996.388\n",
      "03102021 22:55:04|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 16710\n",
      "03102021 22:55:04|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03102021 22:55:04|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 11\n",
      "03102021 22:55:04|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03102021 22:55:04|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373b1719b3d944639d8b7649a46577a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=239.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:57:33|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa5fc5fc4264e6fb37db1c29923bc12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:58:20|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03102021 22:58:20|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.979  |     0.732\n",
      "03102021 22:58:20|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  16710.000  |       N/A\n",
      "03102021 22:58:20|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03102021 22:58:20|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |    11.000  |       N/A\n",
      "03102021 22:58:20|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03102021 22:58:20|INFO|allennlp.training.tensorboard_writer| loss               |     0.076  |     1.227\n",
      "03102021 22:58:20|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03102021 22:58:20|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  4996.388  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 22:58:22|INFO|allennlp.training.checkpointer| Best validation performance so far. Copying weights to '/home/mlepekhin/models/rubert_enru_attacked_15/checkpoints/best.th'.\n",
      "03102021 22:58:27|INFO|allennlp.training.trainer| Epoch duration: 0:03:22.895929\n",
      "03102021 22:58:27|INFO|allennlp.training.trainer| Estimated training time remaining: 0:06:32\n",
      "03102021 22:58:27|INFO|allennlp.training.trainer| Epoch 8/9\n",
      "03102021 22:58:27|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 4996.388\n",
      "03102021 22:58:27|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 16710\n",
      "03102021 22:58:27|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03102021 22:58:27|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 11\n",
      "03102021 22:58:27|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03102021 22:58:27|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac7c78935fe14da3bf066dd09d75bfba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=239.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 23:00:55|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dcba350c22243a491b64c5b26007980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 23:01:43|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03102021 23:01:43|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.986  |     0.716\n",
      "03102021 23:01:43|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  16710.000  |       N/A\n",
      "03102021 23:01:43|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03102021 23:01:43|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |    11.000  |       N/A\n",
      "03102021 23:01:43|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03102021 23:01:43|INFO|allennlp.training.tensorboard_writer| loss               |     0.055  |     1.396\n",
      "03102021 23:01:43|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03102021 23:01:43|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  4996.388  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 23:01:46|INFO|allennlp.training.trainer| Epoch duration: 0:03:18.625882\n",
      "03102021 23:01:46|INFO|allennlp.training.trainer| Estimated training time remaining: 0:03:16\n",
      "03102021 23:01:46|INFO|allennlp.training.trainer| Epoch 9/9\n",
      "03102021 23:01:46|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 4996.512\n",
      "03102021 23:01:46|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 16710\n",
      "03102021 23:01:46|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03102021 23:01:46|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 11\n",
      "03102021 23:01:46|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03102021 23:01:46|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836f78abe97c441fa1a69c39863d4c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=239.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 23:04:15|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31943e2007a7493580604119efa20bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 23:05:03|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03102021 23:05:03|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.993  |     0.716\n",
      "03102021 23:05:03|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  16710.000  |       N/A\n",
      "03102021 23:05:03|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03102021 23:05:03|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |    11.000  |       N/A\n",
      "03102021 23:05:03|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03102021 23:05:03|INFO|allennlp.training.tensorboard_writer| loss               |     0.032  |     1.342\n",
      "03102021 23:05:03|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03102021 23:05:03|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  4996.512  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 23:05:06|INFO|allennlp.training.trainer| Epoch duration: 0:03:20.149939\n",
      "03102021 23:05:06|INFO|allennlp.training.checkpointer| loading best weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "train_loader, dev_loader = build_data_loaders(train_data, dev_data)\n",
    "\n",
    "# You obviously won't want to create a temporary file for your training\n",
    "# results, but for execution in binder for this course, we need to do this.\n",
    "\n",
    "trainer = build_classifier_trainer(\n",
    "    model,\n",
    "    pathjoin(MODELS_DIR, MODEL_ID, 'checkpoints'),\n",
    "    train_loader,\n",
    "    dev_loader,\n",
    "    10,\n",
    "    cuda_device=cuda_device\n",
    ")\n",
    "print(\"Starting training\")\n",
    "trainer.train()\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/home/mlepekhin/models/rubert_enru_attacked_15/checkpoints/*.json': No such file or directory\r\n",
      "rm: cannot remove '/home/mlepekhin/models/rubert_enru_attacked_15/checkpoints/model*': No such file or directory\r\n",
      "rm: cannot remove '/home/mlepekhin/models/rubert_enru_attacked_15/checkpoints/training*': No such file or directory\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 23:37:48|WARNING|root| vocabulary serialization directory /home/mlepekhin/models/rubert_enru_attacked_15/vocab is not empty\n",
      "03102021 23:37:48|INFO|filelock| Lock 140567992680512 acquired on /home/mlepekhin/models/rubert_enru_attacked_15/vocab/.lock\n",
      "03102021 23:37:48|INFO|filelock| Lock 140567992680512 released on /home/mlepekhin/models/rubert_enru_attacked_15/vocab/.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 681M\r\n",
      "-rw-rw-r-- 1 mlepekhin mlepekhin 681M мар 10 22:58 best.th\r\n",
      "drwxrwxr-x 4 mlepekhin mlepekhin 4,0K мар 10 22:32 log\r\n"
     ]
    }
   ],
   "source": [
    "!rm \"{CHECKPOINTS_DIR}\"/*.json \"{CHECKPOINTS_DIR}\"/model* \"{CHECKPOINTS_DIR}\"/training*\n",
    "model.vocab.save_to_files(pathjoin(MODELS_DIR, MODEL_ID, 'vocab'))\n",
    "!ls -lh \"{CHECKPOINTS_DIR}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
