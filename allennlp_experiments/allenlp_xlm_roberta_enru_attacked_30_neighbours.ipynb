{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mseven              \u001b[m  Wed Mar 10 18:02:48 2021  \u001b[1m\u001b[30m440.64\u001b[m\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mTITAN RTX       \u001b[m |\u001b[31m 34'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   11\u001b[m / \u001b[33m24220\u001b[m MB |\r\n",
      "\u001b[36m[1]\u001b[m \u001b[34mTITAN RTX       \u001b[m |\u001b[1m\u001b[31m 71'C\u001b[m, \u001b[1m\u001b[32m 37 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 2662\u001b[m / \u001b[33m24220\u001b[m MB | \u001b[1m\u001b[30mcwb\u001b[m(\u001b[33m2651M\u001b[m)\r\n",
      "\u001b[36m[2]\u001b[m \u001b[34mTITAN RTX       \u001b[m |\u001b[31m 32'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   11\u001b[m / \u001b[33m24220\u001b[m MB |\r\n",
      "\u001b[36m[3]\u001b[m \u001b[34mTITAN RTX       \u001b[m |\u001b[1m\u001b[31m 86'C\u001b[m, \u001b[1m\u001b[32m 98 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 9928\u001b[m / \u001b[33m24220\u001b[m MB | \u001b[1m\u001b[30mcwb\u001b[m(\u001b[33m3411M\u001b[m) \u001b[1m\u001b[30mcwb\u001b[m(\u001b[33m3063M\u001b[m) \u001b[1m\u001b[30mcwb\u001b[m(\u001b[33m3443M\u001b[m)\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as pathjoin\n",
    "from data_processing import *\n",
    "from interpretation import *\n",
    "from models import *\n",
    "from training import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3867, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>changed_words_num</th>\n",
       "      <th>new_model_target</th>\n",
       "      <th>old_model_target</th>\n",
       "      <th>old_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>141</td>\n",
       "      <td>A1</td>\n",
       "      <td>A great way to start , I think , with my view ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>528</td>\n",
       "      <td>A1</td>\n",
       "      <td>Реакция курильщиков на вторую волну антитабачн...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>1049</td>\n",
       "      <td>A9</td>\n",
       "      <td>1 . - ( 1 ) The corporation sole by the name o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1121</td>\n",
       "      <td>A12</td>\n",
       "      <td>We noticed that you 're using an unsupported b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>1755</td>\n",
       "      <td>A14</td>\n",
       "      <td>ПЕРВЫЕ РЕЗУЛЬТАТЫ ЭКСПЕРИМЕНТА ПО РАДИОЛОКАЦИИ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 target                                               text  \\\n",
       "727          141     A1  A great way to start , I think , with my view ...   \n",
       "1420         528     A1  Реакция курильщиков на вторую волну антитабачн...   \n",
       "1031        1049     A9  1 . - ( 1 ) The corporation sole by the name o...   \n",
       "137         1121    A12  We noticed that you 're using an unsupported b...   \n",
       "952         1755    A14  ПЕРВЫЕ РЕЗУЛЬТАТЫ ЭКСПЕРИМЕНТА ПО РАДИОЛОКАЦИИ...   \n",
       "\n",
       "      changed_words_num new_model_target old_model_target old_text  \n",
       "727                 NaN              NaN              NaN      NaN  \n",
       "1420                NaN              NaN              NaN      NaN  \n",
       "1031                NaN              NaN              NaN      NaN  \n",
       "137                 NaN              NaN              NaN      NaN  \n",
       "952                 NaN              NaN              NaN      NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddd = pd.read_csv('/home/mlepekhin/data/ru_train')\n",
    "ddd = ddd.append(pd.read_csv('/home/mlepekhin/data/en_train'))\n",
    "ddd = ddd.append(pd.read_csv('/home/mlepekhin/data/new_ru_attacked_30.csv'))\n",
    "ddd = ddd.append(pd.read_csv('/home/mlepekhin/data/en_attacked_30.csv')).sample(frac=1, random_state=42)\n",
    "print(ddd.shape)\n",
    "ddd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddd.to_csv('enru_attacked_train_30.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/mlepekhin/data'\n",
    "MODELS_DIR = '/home/mlepekhin/models'\n",
    "MODEL_ID = 'allennlp_xlm_roberta_enru_attacked_30' \n",
    "CHECKPOINTS_DIR = pathjoin(MODELS_DIR, MODEL_ID, 'checkpoints')\n",
    "BEST_MODEL = pathjoin(CHECKPOINTS_DIR, 'best.th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = 'xlm-roberta-base'\n",
    "MAX_TOKENS = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:05:44|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03102021 18:05:44|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "03102021 18:05:44|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /home/mlepekhin/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n",
      "03102021 18:05:46|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03102021 18:05:46|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "03102021 18:05:46|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /home/mlepekhin/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n"
     ]
    }
   ],
   "source": [
    "tokenizer = PretrainedTransformerTokenizer(transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:05:52|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03102021 18:05:52|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "03102021 18:05:52|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /home/mlepekhin/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n",
      "03102021 18:05:53|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03102021 18:05:53|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "03102021 18:05:54|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /home/mlepekhin/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n",
      "03102021 18:05:55|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03102021 18:05:55|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "03102021 18:05:56|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /home/mlepekhin/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n",
      "03102021 18:05:57|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03102021 18:05:57|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "03102021 18:05:58|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /home/mlepekhin/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n",
      "03102021 18:05:59|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03102021 18:05:59|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "03102021 18:05:59|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /home/mlepekhin/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n",
      "03102021 18:06:00|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03102021 18:06:00|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "03102021 18:06:01|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /home/mlepekhin/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n",
      "03102021 18:06:02|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03102021 18:06:02|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:06:03|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /home/mlepekhin/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n",
      "03102021 18:06:04|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03102021 18:06:04|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "03102021 18:06:04|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /home/mlepekhin/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n",
      "<class 'data_processing.ClassificationDatasetReader'> enru_attacked_train_30.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79341e3c2e14b87bca81c6bd5f09261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff16b60ca1c48b99830a73b1433e202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:11:34|INFO|allennlp.data.vocabulary| Fitting token dictionary from dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building the vocabulary\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a28f21a432413d991ee64b7652ef68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7420.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset_reader = build_transformer_dataset_reader(transformer_model, lower=True)\n",
    "val_dataset_reader = build_transformer_dataset_reader(transformer_model, lower=True)\n",
    "\n",
    "train_data, dev_data = read_data(\n",
    "    \"enru_attacked_train_30.csv\", \n",
    "    pathjoin(DATA_DIR, \"manual_genres\", \"all.csv\"),\n",
    "    train_dataset_reader, \n",
    "    val_dataset_reader\n",
    ")\n",
    "\n",
    "vocab = build_vocab(train_data + dev_data)\n",
    "\n",
    "train_data.index_with(vocab)\n",
    "dev_data.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:11:34|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03102021 18:11:34|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "03102021 18:11:35|INFO|transformers.modeling_utils| loading weights file https://cdn.huggingface.co/xlm-roberta-base-pytorch_model.bin from cache at /home/mlepekhin/.cache/torch/transformers/5cbeb972feded79b927818648bf14dc71b7810cda88c8c971a9d45c0dab901ec.aeeaca90954dc20ffa2909de722cfbfd455c5bb16d480c5bdf6d7fe79c68c267\n",
      "03102021 18:11:46|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03102021 18:11:46|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "03102021 18:11:46|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /home/mlepekhin/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n",
      "03102021 18:11:47|INFO|transformers.configuration_utils| loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-config.json from cache at /home/mlepekhin/.cache/torch/transformers/762ddd751172e9d3229e5da17a459eee6c0dfdc237c718944d0b1a85f06c7e1e.2b0f807393c56e8861a31cd67d2fc0b45d71d9735dd47dd66afb650f90b6d2a8\n",
      "03102021 18:11:47|INFO|transformers.configuration_utils| Model config XLMRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "03102021 18:11:48|INFO|transformers.tokenization_utils| loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-roberta-base-sentencepiece.bpe.model from cache at /home/mlepekhin/.cache/torch/transformers/0c370616ddfc06067c0634160f749c2cf9d8da2c50e03a2617ce5841c8df3b1d.309f0c29486cffc28e1e40a2ab0ac8f500c203fe080b95f820aa9cb58e5b84ed\n"
     ]
    }
   ],
   "source": [
    "model = build_pool_transformer_model(vocab, transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    cuda_device = 0\n",
    "    model = model.cuda(cuda_device)\n",
    "else:\n",
    "    cuda_device = -1\n",
    "print(cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {CHECKPOINTS_DIR}\n",
    "!mkdir -p {CHECKPOINTS_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:11:52|INFO|allennlp.training.optimizers| Number of trainable parameters: 278052107\n",
      "03102021 18:11:52|WARNING|allennlp.training.trainer| You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n",
      "03102021 18:11:52|INFO|allennlp.training.trainer| Beginning training.\n",
      "03102021 18:11:52|INFO|allennlp.training.trainer| Epoch 0/9\n",
      "03102021 18:11:52|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5927.872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:11:52|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 1990\n",
      "03102021 18:11:52|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03102021 18:11:52|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 11\n",
      "03102021 18:11:52|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03102021 18:11:52|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e34af7ed63e4b438d42866164a0580d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=242.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:14:07|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d293e1746f82413bad2eae4b28c09ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:14:49|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03102021 18:14:49|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.684  |     0.715\n",
      "03102021 18:14:49|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  1990.000  |       N/A\n",
      "03102021 18:14:49|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03102021 18:14:49|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |    11.000  |       N/A\n",
      "03102021 18:14:49|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03102021 18:14:49|INFO|allennlp.training.tensorboard_writer| loss               |     1.007  |     0.861\n",
      "03102021 18:14:49|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03102021 18:14:49|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5927.872  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:14:53|INFO|allennlp.training.checkpointer| Best validation performance so far. Copying weights to '/home/mlepekhin/models/allennlp_xlm_roberta_enru_attacked_30/checkpoints/best.th'.\n",
      "03102021 18:14:54|INFO|allennlp.training.trainer| Epoch duration: 0:03:01.657485\n",
      "03102021 18:14:54|INFO|allennlp.training.trainer| Estimated training time remaining: 0:27:14\n",
      "03102021 18:14:54|INFO|allennlp.training.trainer| Epoch 1/9\n",
      "03102021 18:14:54|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5927.872\n",
      "03102021 18:14:54|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 18526\n",
      "03102021 18:14:54|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03102021 18:14:54|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 18470\n",
      "03102021 18:14:54|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03102021 18:14:54|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535e8ff1d6de4a67b8c600b4c2d956e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=242.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:17:23|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba79efc1302475f9eecf32028873940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:18:08|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03102021 18:18:08|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.839  |     0.728\n",
      "03102021 18:18:08|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  18526.000  |       N/A\n",
      "03102021 18:18:08|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03102021 18:18:08|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  18470.000  |       N/A\n",
      "03102021 18:18:08|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03102021 18:18:08|INFO|allennlp.training.tensorboard_writer| loss               |     0.502  |     0.893\n",
      "03102021 18:18:08|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03102021 18:18:08|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5927.872  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:18:12|INFO|allennlp.training.checkpointer| Best validation performance so far. Copying weights to '/home/mlepekhin/models/allennlp_xlm_roberta_enru_attacked_30/checkpoints/best.th'.\n",
      "03102021 18:18:19|INFO|allennlp.training.trainer| Epoch duration: 0:03:25.701921\n",
      "03102021 18:18:19|INFO|allennlp.training.trainer| Estimated training time remaining: 0:25:49\n",
      "03102021 18:18:19|INFO|allennlp.training.trainer| Epoch 2/9\n",
      "03102021 18:18:19|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5927.872\n",
      "03102021 18:18:20|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 18526\n",
      "03102021 18:18:20|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03102021 18:18:20|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 18526\n",
      "03102021 18:18:20|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03102021 18:18:20|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5abda4b84ebc49b2a4ca788407c35189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=242.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:20:47|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91dbd7aa587f40769db5234a709c6316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:21:31|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03102021 18:21:31|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.899  |     0.715\n",
      "03102021 18:21:31|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  18526.000  |       N/A\n",
      "03102021 18:21:31|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03102021 18:21:31|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  18526.000  |       N/A\n",
      "03102021 18:21:31|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03102021 18:21:31|INFO|allennlp.training.tensorboard_writer| loss               |     0.331  |     0.965\n",
      "03102021 18:21:31|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03102021 18:21:31|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5927.872  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:21:37|INFO|allennlp.training.trainer| Epoch duration: 0:03:17.294552\n",
      "03102021 18:21:37|INFO|allennlp.training.trainer| Estimated training time remaining: 0:22:44\n",
      "03102021 18:21:37|INFO|allennlp.training.trainer| Epoch 3/9\n",
      "03102021 18:21:37|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5927.872\n",
      "03102021 18:21:37|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 18526\n",
      "03102021 18:21:37|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03102021 18:21:37|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 18526\n",
      "03102021 18:21:37|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03102021 18:21:37|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e24dcce61a74effbd3947052dab8b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=242.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:24:04|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a57454e2f42641aa8af5114a80369c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:24:48|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03102021 18:24:48|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.936  |     0.745\n",
      "03102021 18:24:48|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  18526.000  |       N/A\n",
      "03102021 18:24:48|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03102021 18:24:48|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  18526.000  |       N/A\n",
      "03102021 18:24:48|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03102021 18:24:48|INFO|allennlp.training.tensorboard_writer| loss               |     0.218  |     0.945\n",
      "03102021 18:24:48|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03102021 18:24:48|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5927.872  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:24:52|INFO|allennlp.training.checkpointer| Best validation performance so far. Copying weights to '/home/mlepekhin/models/allennlp_xlm_roberta_enru_attacked_30/checkpoints/best.th'.\n",
      "03102021 18:25:00|INFO|allennlp.training.trainer| Epoch duration: 0:03:22.765607\n",
      "03102021 18:25:00|INFO|allennlp.training.trainer| Estimated training time remaining: 0:19:41\n",
      "03102021 18:25:00|INFO|allennlp.training.trainer| Epoch 4/9\n",
      "03102021 18:25:00|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5927.872\n",
      "03102021 18:25:00|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 18526\n",
      "03102021 18:25:00|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03102021 18:25:00|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 18526\n",
      "03102021 18:25:00|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03102021 18:25:00|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e76250748a447949986df08142fc735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=242.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:27:26|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09cabc324fc34faaa33501876c6d20d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:28:10|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03102021 18:28:10|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.959  |     0.750\n",
      "03102021 18:28:10|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  18526.000  |       N/A\n",
      "03102021 18:28:10|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03102021 18:28:10|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  18526.000  |       N/A\n",
      "03102021 18:28:10|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03102021 18:28:10|INFO|allennlp.training.tensorboard_writer| loss               |     0.130  |     0.953\n",
      "03102021 18:28:10|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03102021 18:28:10|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5927.872  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:28:15|INFO|allennlp.training.checkpointer| Best validation performance so far. Copying weights to '/home/mlepekhin/models/allennlp_xlm_roberta_enru_attacked_30/checkpoints/best.th'.\n",
      "03102021 18:28:22|INFO|allennlp.training.trainer| Epoch duration: 0:03:22.857624\n",
      "03102021 18:28:22|INFO|allennlp.training.trainer| Estimated training time remaining: 0:16:30\n",
      "03102021 18:28:22|INFO|allennlp.training.trainer| Epoch 5/9\n",
      "03102021 18:28:22|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5927.872\n",
      "03102021 18:28:23|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 18526\n",
      "03102021 18:28:23|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03102021 18:28:23|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 18526\n",
      "03102021 18:28:23|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03102021 18:28:23|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7289581a8c422d9145f12cc75831f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=242.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:30:48|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c58f65667c78467f808689e19cb3de2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:31:33|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03102021 18:31:33|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.960  |     0.748\n",
      "03102021 18:31:33|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  18526.000  |       N/A\n",
      "03102021 18:31:33|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03102021 18:31:33|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  18526.000  |       N/A\n",
      "03102021 18:31:33|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03102021 18:31:33|INFO|allennlp.training.tensorboard_writer| loss               |     0.122  |     1.013\n",
      "03102021 18:31:33|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03102021 18:31:33|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5927.872  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:31:37|INFO|allennlp.training.trainer| Epoch duration: 0:03:14.509460\n",
      "03102021 18:31:37|INFO|allennlp.training.trainer| Estimated training time remaining: 0:13:09\n",
      "03102021 18:31:37|INFO|allennlp.training.trainer| Epoch 6/9\n",
      "03102021 18:31:37|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5927.872\n",
      "03102021 18:31:37|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 18526\n",
      "03102021 18:31:37|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03102021 18:31:37|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 18526\n",
      "03102021 18:31:37|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03102021 18:31:37|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5dd1c2cea3940a3bec1f881e622a813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=242.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:34:04|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57860003c1994abfa5d9b8617cb97367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:34:48|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03102021 18:34:48|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.975  |     0.731\n",
      "03102021 18:34:48|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  18526.000  |       N/A\n",
      "03102021 18:34:48|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03102021 18:34:48|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  18526.000  |       N/A\n",
      "03102021 18:34:48|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03102021 18:34:48|INFO|allennlp.training.tensorboard_writer| loss               |     0.078  |     1.155\n",
      "03102021 18:34:48|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03102021 18:34:48|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5927.872  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:34:52|INFO|allennlp.training.trainer| Epoch duration: 0:03:15.385116\n",
      "03102021 18:34:52|INFO|allennlp.training.trainer| Estimated training time remaining: 0:09:51\n",
      "03102021 18:34:52|INFO|allennlp.training.trainer| Epoch 7/9\n",
      "03102021 18:34:52|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5927.872\n",
      "03102021 18:34:53|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 18526\n",
      "03102021 18:34:53|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03102021 18:34:53|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 18526\n",
      "03102021 18:34:53|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03102021 18:34:53|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d350d7a6b3f4ec0871b58c546ac7272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=242.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:37:19|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713644c68bbb493ab29786fbfbe8f974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:38:03|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03102021 18:38:03|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.984  |     0.747\n",
      "03102021 18:38:03|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  18526.000  |       N/A\n",
      "03102021 18:38:03|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03102021 18:38:03|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  18526.000  |       N/A\n",
      "03102021 18:38:03|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03102021 18:38:03|INFO|allennlp.training.tensorboard_writer| loss               |     0.059  |     1.105\n",
      "03102021 18:38:03|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03102021 18:38:03|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5927.872  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:38:08|INFO|allennlp.training.trainer| Epoch duration: 0:03:15.442649\n",
      "03102021 18:38:08|INFO|allennlp.training.trainer| Estimated training time remaining: 0:06:33\n",
      "03102021 18:38:08|INFO|allennlp.training.trainer| Epoch 8/9\n",
      "03102021 18:38:08|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5927.872\n",
      "03102021 18:38:08|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 18526\n",
      "03102021 18:38:08|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03102021 18:38:08|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 18526\n",
      "03102021 18:38:08|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03102021 18:38:08|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035bafee3b8a47cdb29177c153309664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=242.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:40:34|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b58e6a1fd54431ac60d02bdea8cc5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:41:19|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03102021 18:41:19|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.989  |     0.744\n",
      "03102021 18:41:19|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  18526.000  |       N/A\n",
      "03102021 18:41:19|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03102021 18:41:19|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  18526.000  |       N/A\n",
      "03102021 18:41:19|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03102021 18:41:19|INFO|allennlp.training.tensorboard_writer| loss               |     0.031  |     1.147\n",
      "03102021 18:41:19|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03102021 18:41:19|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5927.872  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:41:23|INFO|allennlp.training.trainer| Epoch duration: 0:03:15.130420\n",
      "03102021 18:41:23|INFO|allennlp.training.trainer| Estimated training time remaining: 0:03:16\n",
      "03102021 18:41:23|INFO|allennlp.training.trainer| Epoch 9/9\n",
      "03102021 18:41:23|INFO|allennlp.training.trainer| Worker 0 memory usage MB: 5927.872\n",
      "03102021 18:41:23|INFO|allennlp.training.trainer| GPU 0 memory usage MB: 18526\n",
      "03102021 18:41:23|INFO|allennlp.training.trainer| GPU 1 memory usage MB: 2662\n",
      "03102021 18:41:23|INFO|allennlp.training.trainer| GPU 2 memory usage MB: 18526\n",
      "03102021 18:41:23|INFO|allennlp.training.trainer| GPU 3 memory usage MB: 9928\n",
      "03102021 18:41:23|INFO|allennlp.training.trainer| Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0352613495047b48fff9da6e8b1756b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=242.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:43:50|INFO|allennlp.training.trainer| Validating\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47a01c68a6e45dea5ebbfbbe2a8f104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:44:35|INFO|allennlp.training.tensorboard_writer|                        Training |  Validation\n",
      "03102021 18:44:35|INFO|allennlp.training.tensorboard_writer| accuracy           |     0.988  |     0.742\n",
      "03102021 18:44:35|INFO|allennlp.training.tensorboard_writer| gpu_0_memory_MB    |  18526.000  |       N/A\n",
      "03102021 18:44:35|INFO|allennlp.training.tensorboard_writer| gpu_1_memory_MB    |  2662.000  |       N/A\n",
      "03102021 18:44:35|INFO|allennlp.training.tensorboard_writer| gpu_2_memory_MB    |  18526.000  |       N/A\n",
      "03102021 18:44:35|INFO|allennlp.training.tensorboard_writer| gpu_3_memory_MB    |  9928.000  |       N/A\n",
      "03102021 18:44:35|INFO|allennlp.training.tensorboard_writer| loss               |     0.037  |     1.237\n",
      "03102021 18:44:35|INFO|allennlp.training.tensorboard_writer| reg_loss           |     0.000  |     0.000\n",
      "03102021 18:44:35|INFO|allennlp.training.tensorboard_writer| worker_0_memory_MB |  5927.872  |       N/A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:44:39|INFO|allennlp.training.trainer| Epoch duration: 0:03:16.404866\n",
      "03102021 18:44:39|INFO|allennlp.training.checkpointer| loading best weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "train_loader, dev_loader = build_data_loaders(train_data, dev_data)\n",
    "\n",
    "# You obviously won't want to create a temporary file for your training\n",
    "# results, but for execution in binder for this course, we need to do this.\n",
    "\n",
    "trainer = build_classifier_trainer(\n",
    "    model,\n",
    "    pathjoin(MODELS_DIR, MODEL_ID, 'checkpoints'),\n",
    "    train_loader,\n",
    "    dev_loader,\n",
    "    10,\n",
    "    cuda_device=cuda_device\n",
    ")\n",
    "print(\"Starting training\")\n",
    "trainer.train()\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03102021 18:44:41|WARNING|root| vocabulary serialization directory /home/mlepekhin/models/allennlp_xlm_roberta_enru_attacked_30/vocab is not empty\n",
      "03102021 18:44:41|INFO|filelock| Lock 140457197761488 acquired on /home/mlepekhin/models/allennlp_xlm_roberta_enru_attacked_30/vocab/.lock\n",
      "03102021 18:44:42|INFO|filelock| Lock 140457197761488 released on /home/mlepekhin/models/allennlp_xlm_roberta_enru_attacked_30/vocab/.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1,1G\r\n",
      "-rw-rw-r-- 1 mlepekhin mlepekhin 1,1G мар 10 18:28 best.th\r\n",
      "drwxrwxr-x 4 mlepekhin mlepekhin 4,0K мар 10 18:11 log\r\n"
     ]
    }
   ],
   "source": [
    "!rm \"{CHECKPOINTS_DIR}\"/*.json \"{CHECKPOINTS_DIR}\"/model* \"{CHECKPOINTS_DIR}\"/training*\n",
    "model.vocab.save_to_files(pathjoin(MODELS_DIR, MODEL_ID, 'vocab'))\n",
    "!ls -lh \"{CHECKPOINTS_DIR}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
